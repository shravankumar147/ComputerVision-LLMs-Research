{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8335eff4-f9ed-4f1a-ac08-61ac93e1d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.06403858959674835\n",
      "Epoch 2: Loss = 0.00019464935758151114\n",
      "Epoch 3: Loss = 0.0003507118090055883\n",
      "Epoch 4: Loss = 0.0002638925798237324\n",
      "Epoch 5: Loss = 0.00013713787484448403\n",
      "Epoch 6: Loss = 0.00023284090275410563\n",
      "Epoch 7: Loss = 0.0003437346313148737\n",
      "Epoch 8: Loss = 5.882755795028061e-05\n",
      "Epoch 9: Loss = 7.724326860625297e-05\n",
      "Epoch 10: Loss = 0.0001516813790658489\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Dinov2ForImageClassification, AutoImageProcessor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directories\n",
    "base_dir = \"/home/shravan/documents/deeplearning/github/ComputerVision-Research/finetuning/roam2/\"\n",
    "sample_dir = os.path.join(base_dir, \"data/support_samples/\")\n",
    "support_csv_path = os.path.join(base_dir, \"data/support.csv\")\n",
    "\n",
    "# Load the support_df\n",
    "support_df = pd.read_csv(support_csv_path)\n",
    "\n",
    "# Initialize processor\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-small-imagenet1k-1-layer\")\n",
    "\n",
    "# Load and preprocess support samples\n",
    "def preprocess_support_samples(samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in samples.iterrows():\n",
    "        image_path = os.path.join(sample_dir, f\"{row['id']}.jpg\")\n",
    "        image = Image.open(image_path)\n",
    "        processed_image = processor(image, return_tensors=\"pt\").pixel_values.squeeze(0)  # Remove batch dimension\n",
    "        images.append(processed_image)\n",
    "        labels.append(row['label'] - 1)  # Ensure labels are 0-based\n",
    "    return images, labels\n",
    "\n",
    "images, labels = preprocess_support_samples(support_df)\n",
    "\n",
    "# Prepare dataset\n",
    "images_tensor = torch.stack(images)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "dataset = TensorDataset(images_tensor, labels_tensor)\n",
    "\n",
    "# Create DataLoader\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Load model and adjust the classifier layer\n",
    "model = Dinov2ForImageClassification.from_pretrained(\n",
    "    \"facebook/dinov2-small-imagenet1k-1-layer\", \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Reinitialize classifier layer to match the number of classes\n",
    "# Make sure the `in_features` matches the output size of the previous layer\n",
    "model.classifier = torch.nn.Linear(in_features=768, out_features=3)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move model to appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Finetune the model\n",
    "model.train()\n",
    "for epoch in range(10):  # Use fewer epochs for debugging\n",
    "    for batch in loader:\n",
    "        images_batch, labels_batch = batch\n",
    "        images_batch = images_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = torch.nn.functional.cross_entropy(outputs.logits, labels_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}: Loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58df63c4-d54a-4209-99c5-fedcb45dd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the finetuned model\n",
    "model.save_pretrained(\"./finetuned_dinov2_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f783c1b-5ee3-4afc-8458-8fc4db0561bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dinov2ForImageClassification(\n",
       "  (dinov2): Dinov2Model(\n",
       "    (embeddings): Dinov2Embeddings(\n",
       "      (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Dinov2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x Dinov2Layer(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attention): Dinov2Attention(\n",
       "            (attention): Dinov2SelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): Dinov2SelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (layer_scale1): Dinov2LayerScale()\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Dinov2MLP(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          )\n",
       "          (layer_scale2): Dinov2LayerScale()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fdfd7e53-2903-429d-9c97-fb6f2c8b3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = os.path.join(base_dir, \"data/solutionAugust5.csv\")\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df8b5e9c-8821-472e-a953-83c146414590",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "142cb3d0-5bc9-4743-8d2f-7da29c75e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Iterate over the images and make predictions\n",
    "image_dir = os.path.join(base_dir, \"data/evaluation_data/\")\n",
    "for idx, row in df.iterrows():\n",
    "    # Construct the full image path\n",
    "    image_filename = f\"{row['id']}.jpg\"\n",
    "    image_path = os.path.join(image_dir, image_filename)\n",
    "    \n",
    "    # Open and process the image\n",
    "    image = Image.open(image_path)\n",
    "    inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "    # Move inputs to the same device as the model\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "    \n",
    "    # Append the prediction to the list\n",
    "    predictions.append({'id': row['id'], 'label': predicted_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e482d9f-c198-447e-a1b7-7ce087e73692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a DataFrame\n",
    "submission_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save the submission DataFrame to a CSV file with the required format\n",
    "submission_file_path = os.path.join(base_dir, \"submission.csv\")\n",
    "submission_df.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7168b45c-9049-436d-8f92-e220dd66a53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afc50dc671ea44fb8375b560c8019b43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>621af6f5776541c78bf344b177bdb7ad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1287bddbad1c47e79965dfb5458b8098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a735c1ba09cb47f8be1f21cbdb95c84e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6142dd35c4e4a888b9fb835c38cb6e2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  label\n",
       "0  afc50dc671ea44fb8375b560c8019b43      1\n",
       "1  621af6f5776541c78bf344b177bdb7ad      0\n",
       "2  1287bddbad1c47e79965dfb5458b8098      0\n",
       "3  a735c1ba09cb47f8be1f21cbdb95c84e      0\n",
       "4  b6142dd35c4e4a888b9fb835c38cb6e2      0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e4ac615-3a22-47c2-ba8c-a96a0e5acfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id\n",
       "label      \n",
       "0      4246\n",
       "1       754"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78ba97a4-b4e0-4fd6-ab2d-97b5bcd14931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5815db1-d81f-4509-92f7-0f9ef16a4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62909b8d-60ec-42e6-9bbe-2616fcf36529",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = submission_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70edc398-e133-47da-bac4-23f0b07be4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometric Mean Weighted F1-Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shravan/anaconda3/envs/hf_dev/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score for each class\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Calculate the weighted geometric mean of F1-Scores\n",
    "def geometric_mean(f1_scores, weights):\n",
    "    \"\"\"Calculate the weighted geometric mean of F1-scores.\"\"\"\n",
    "    f1_scores = np.array(f1_scores)\n",
    "    weights = np.array(weights)\n",
    "    weighted_f1 = np.power(np.prod(np.power(f1_scores, weights)), 1.0 / np.sum(weights))\n",
    "    return weighted_f1\n",
    "\n",
    "# Get class frequencies (weights for each class)\n",
    "class_weights = np.bincount(true_labels) / len(true_labels)\n",
    "\n",
    "# Calculate weighted geometric mean F1-Score\n",
    "weighted_geom_mean_f1 = geometric_mean(f1, class_weights)\n",
    "\n",
    "print(f\"Geometric Mean Weighted F1-Score: {weighted_geom_mean_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b0edb-64db-47e2-8140-3c3e16977ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-dev",
   "language": "python",
   "name": "hf_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
