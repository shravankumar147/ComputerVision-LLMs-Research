{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shravankumar147/interior-or-exterior-classification-using-qwen2vl?scriptVersionId=219816823\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\nfrom PIL import Image\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:04:22.051704Z","iopub.execute_input":"2025-01-29T17:04:22.052026Z","iopub.status.idle":"2025-01-29T17:04:45.752327Z","shell.execute_reply.started":"2025-01-29T17:04:22.051994Z","shell.execute_reply":"2025-01-29T17:04:45.751535Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import requests\nfrom io import BytesIO\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:23:05.84781Z","iopub.execute_input":"2025-01-29T17:23:05.848107Z","iopub.status.idle":"2025-01-29T17:23:05.852123Z","shell.execute_reply.started":"2025-01-29T17:23:05.848085Z","shell.execute_reply":"2025-01-29T17:23:05.851239Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Load model and processor\nmodel = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-2B-Instruct\",\n    trust_remote_code=True,\n    torch_dtype=torch.float16\n).to(\"cuda\").eval()\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", trust_remote_code=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:04:45.753177Z","iopub.execute_input":"2025-01-29T17:04:45.753733Z","iopub.status.idle":"2025-01-29T17:06:40.565181Z","shell.execute_reply.started":"2025-01-29T17:04:45.753706Z","shell.execute_reply":"2025-01-29T17:06:40.564203Z"}},"outputs":[{"name":"stderr","text":"The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cc8769e1c5e454cbef504a35fdd632d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a6607e51cc042b9b7c1c11084e63499"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a501a5ca66b4204a5a31b2ef42f5a30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31506d5bd915496ab5c8cdfed89059db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb33eca5c1b64f7294a15a4bd0959971"}},"metadata":{}},{"name":"stderr","text":"`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4efd2294d14f8cabce327a5dbaa498"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73ab7d5f5c84acf94159fe11d259740"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b684702f4f484ab2b7545a86e356a300"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"886831094fd142d288830388d0cfd71e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cee84d131944548b72a55dd7f08c101"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd68d07eff774889b3e6c68bae7cb964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0b516d8181b4d2da9d935079fa89284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed6fa32cfd2246b1af6d8473da10b8e4"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def load_image_from_url(url):\n    \"\"\"Load image from URL using requests\"\"\"\n    response = requests.get(url, timeout=10)\n    response.raise_for_status()\n    return Image.open(BytesIO(response.content)).convert(\"RGB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:09:56.057974Z","iopub.execute_input":"2025-01-29T17:09:56.058367Z","iopub.status.idle":"2025-01-29T17:09:56.062919Z","shell.execute_reply.started":"2025-01-29T17:09:56.058335Z","shell.execute_reply":"2025-01-29T17:09:56.061854Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Example usage\ndef test_model(image_url, question):\n    # Load and process image\n    # image = Image.open(image_path)\n\n    # Load image directly from URL\n    image = load_image_from_url(image_url)\n    \n    # Create message template\n    messages = [{\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": image},\n            {\"type\": \"text\", \"text\": question}\n        ]\n    }]\n    \n    # Process inputs\n    text_prompt = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = processor(\n        text=[text_prompt],\n        images=[image],\n        return_tensors=\"pt\",\n        padding=True\n    ).to(\"cuda\")\n\n    # # Generate response\n    # generated_ids = model.generate(**inputs, max_new_tokens=1024)\n    # return processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\n    # Generate response\n    generated_ids = model.generate(**inputs, max_new_tokens=10)\n    full_response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    \n    # Extract only the classification\n    match = re.search(r'\\b(Interior|Exterior)\\b', full_response, re.IGNORECASE)\n    return match.group(0) if match else \"Classification failed\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:23:10.03234Z","iopub.execute_input":"2025-01-29T17:23:10.032639Z","iopub.status.idle":"2025-01-29T17:23:10.038729Z","shell.execute_reply.started":"2025-01-29T17:23:10.032617Z","shell.execute_reply":"2025-01-29T17:23:10.037742Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"![image](https://www.shutterstock.com/image-photo/dark-car-interior-steering-wheel-600nw-2445598523.jpg)","metadata":{}},{"cell_type":"code","source":"# Example with online image\nimage_url = \"https://www.shutterstock.com/image-photo/dark-car-interior-steering-wheel-600nw-2445598523.jpg\"\nquestion = \"Classify image as Interior or Exterior, Just Interior or Exterior is enough, no further description is required\"\nprint(test_model(image_url, question))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:23:12.163455Z","iopub.execute_input":"2025-01-29T17:23:12.163762Z","iopub.status.idle":"2025-01-29T17:23:12.890965Z","shell.execute_reply.started":"2025-01-29T17:23:12.163741Z","shell.execute_reply":"2025-01-29T17:23:12.890126Z"}},"outputs":[{"name":"stdout","text":"Interior\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# After loading the model:\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"Parameters: {total_params / 1e9:.2f} B\")          # ~2.00 B parameters\nprint(f\"Memory: {total_params * 2 / (1024**3):.2f} GB\")   # ~3.73 GB for float16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:24:00.539521Z","iopub.execute_input":"2025-01-29T17:24:00.53988Z","iopub.status.idle":"2025-01-29T17:24:00.548071Z","shell.execute_reply.started":"2025-01-29T17:24:00.539855Z","shell.execute_reply":"2025-01-29T17:24:00.546919Z"}},"outputs":[{"name":"stdout","text":"Parameters: 2.21 B\nMemory: 4.11 GB\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(f\"VRAM Used: {torch.cuda.memory_allocated() / (1024 ** 3):.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:24:39.719585Z","iopub.execute_input":"2025-01-29T17:24:39.719948Z","iopub.status.idle":"2025-01-29T17:24:39.725003Z","shell.execute_reply.started":"2025-01-29T17:24:39.71992Z","shell.execute_reply":"2025-01-29T17:24:39.723878Z"}},"outputs":[{"name":"stdout","text":"VRAM Used: 4.13 GB\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}