{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shravankumar147/qwen2-vl-2b-instruct-int2-cpu?scriptVersionId=207622679\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:38:57.416747Z","iopub.execute_input":"2024-11-15T17:38:57.417611Z","iopub.status.idle":"2024-11-15T17:38:58.40733Z","shell.execute_reply.started":"2024-11-15T17:38:57.417568Z","shell.execute_reply":"2024-11-15T17:38:58.406276Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/transformers qwen-vl-utils  quanto accelerate \n# flash-attn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-15T17:38:59.802172Z","iopub.execute_input":"2024-11-15T17:38:59.802584Z","iopub.status.idle":"2024-11-15T17:39:53.307611Z","shell.execute_reply.started":"2024-11-15T17:38:59.802545Z","shell.execute_reply":"2024-11-15T17:39:53.306418Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\nfrom transformers import QuantoConfig\nfrom qwen_vl_utils import process_vision_info\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:39:53.309816Z","iopub.execute_input":"2024-11-15T17:39:53.310147Z","iopub.status.idle":"2024-11-15T17:40:11.025227Z","shell.execute_reply.started":"2024-11-15T17:39:53.310113Z","shell.execute_reply":"2024-11-15T17:40:11.024447Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"quantization_config = QuantoConfig(weights=\"int2\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:40:11.026341Z","iopub.execute_input":"2024-11-15T17:40:11.026872Z","iopub.status.idle":"2024-11-15T17:40:11.031251Z","shell.execute_reply.started":"2024-11-15T17:40:11.026838Z","shell.execute_reply":"2024-11-15T17:40:11.030254Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:40:11.033478Z","iopub.execute_input":"2024-11-15T17:40:11.033829Z","iopub.status.idle":"2024-11-15T17:40:11.056843Z","shell.execute_reply.started":"2024-11-15T17:40:11.033789Z","shell.execute_reply":"2024-11-15T17:40:11.055926Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:40:11.059826Z","iopub.execute_input":"2024-11-15T17:40:11.06017Z","iopub.status.idle":"2024-11-15T17:40:11.122653Z","shell.execute_reply.started":"2024-11-15T17:40:11.060139Z","shell.execute_reply":"2024-11-15T17:40:11.121683Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"GPU = Tesla P100-PCIE-16GB. Max memory = 15.888 GB.\n0.0 GB of memory reserved.\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import init_empty_weights, infer_auto_device_map\nfrom transformers import BitsAndBytesConfig\n\n# device_map = infer_auto_device_map(model, max_memory={\"0\": \"14GiB\", \"cpu\": \"30GiB\"})\n# model = model.from_pretrained(\n#     \"your-model\",\n#     device_map=device_map,\n#     load_in_8bit=True,  # Use 8-bit quantization if supported\n#     quantization_config=BitsAndBytesConfig()\n# )\n","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:41:26.136042Z","iopub.execute_input":"2024-11-15T17:41:26.137072Z","iopub.status.idle":"2024-11-15T17:41:26.142278Z","shell.execute_reply.started":"2024-11-15T17:41:26.13702Z","shell.execute_reply":"2024-11-15T17:41:26.141123Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\n# default: Load the model on the available device(s)\n# model = Qwen2VLForConditionalGeneration.from_pretrained(\n#     \"Qwen/Qwen2-VL-2B-Instruct\", \n#     torch_dtype=\"auto\", \n#     quantization_config=quantization_config,\n#     device_map=\"auto\"\n# )\n\n\nmodel = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-2B-Instruct\", \n    torch_dtype=\"auto\", \n    quantization_config=quantization_config,\n    device_map=\"cpu\"\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:41:41.243463Z","iopub.execute_input":"2024-11-15T17:41:41.243848Z","iopub.status.idle":"2024-11-15T17:43:37.092368Z","shell.execute_reply.started":"2024-11-15T17:41:41.243813Z","shell.execute_reply":"2024-11-15T17:43:37.091381Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e547e19b903e4d088721d188cf90700c"}},"metadata":{}},{"name":"stderr","text":"Importing from quanto will be deprecated in v4.47. Please install optimum-quanto instrad `pip install optimum-quanto`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5137b035c0454c05b3cbf835a417531a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfd6a3730c7647b0921e6101fcc8a122"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e875124afcc41a082729af413a2616f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36b7d78c983e4d50a530c7f6d5163963"}},"metadata":{}},{"name":"stderr","text":"`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\nImporting from quanto will be deprecated in v4.47. Please install optimum-quanto instead `pip install optimum-quanto`\nImporting from quanto will be deprecated in v4.47. Please install optimum-quanto instrad `pip install optimum-quanto`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7138683a4d334b588b04b1caca6d109f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f23e91729576496f9677dc541bca1c56"}},"metadata":{}}]},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_model = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nmodel_percentage = round(used_memory_for_model/max_memory*100, 3)\n# print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n# print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_model} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {model_percentage} %.\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:43:49.304519Z","iopub.execute_input":"2024-11-15T17:43:49.304921Z","iopub.status.idle":"2024-11-15T17:43:49.312253Z","shell.execute_reply.started":"2024-11-15T17:43:49.304884Z","shell.execute_reply":"2024-11-15T17:43:49.311312Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Peak reserved memory = 0.0 GB.\nPeak reserved memory for training = 0.0 GB.\nPeak reserved memory % of max memory = 0.0 %.\nPeak reserved memory for training % of max memory = 0.0 %.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n# model = Qwen2VLForConditionalGeneration.from_pretrained(\n#     \"Qwen/Qwen2-VL-2B-Instruct\",\n#     torch_dtype=torch.bfloat16,\n#     attn_implementation=\"flash_attention_2\",\n#     device_map=\"auto\",\n# )\n\n# default processer\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:43:50.454289Z","iopub.execute_input":"2024-11-15T17:43:50.454654Z","iopub.status.idle":"2024-11-15T17:43:53.89369Z","shell.execute_reply.started":"2024-11-15T17:43:50.454621Z","shell.execute_reply":"2024-11-15T17:43:53.892654Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81e155d603bf487799c037074858d003"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0b572011aa04e71a7cec0509b2bbfea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"658aefbad2854a5c88c0797d9578f6c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fb520a38c6d43ef9a78602d02775628"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0d0159fe514d69be008eda698fa52e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a366f8f4a01439aa654f0bafc11cbde"}},"metadata":{}}]},{"cell_type":"code","source":"# The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.\n# min_pixels = 256*28*28\n# max_pixels = 1280*28*28\n# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"image\",\n                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\n            },\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\n\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:44:02.783045Z","iopub.execute_input":"2024-11-15T17:44:02.783728Z","iopub.status.idle":"2024-11-15T17:44:02.804756Z","shell.execute_reply.started":"2024-11-15T17:44:02.783686Z","shell.execute_reply":"2024-11-15T17:44:02.803795Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"text","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:44:10.677947Z","iopub.execute_input":"2024-11-15T17:44:10.678809Z","iopub.status.idle":"2024-11-15T17:44:10.685301Z","shell.execute_reply.started":"2024-11-15T17:44:10.678767Z","shell.execute_reply":"2024-11-15T17:44:10.684445Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'"},"metadata":{}}]},{"cell_type":"code","source":"image_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\n# inputs = inputs.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:44:37.634117Z","iopub.execute_input":"2024-11-15T17:44:37.634537Z","iopub.status.idle":"2024-11-15T17:44:39.84558Z","shell.execute_reply.started":"2024-11-15T17:44:37.634501Z","shell.execute_reply":"2024-11-15T17:44:39.844552Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Inference: Generation of the output\ngenerated_ids = model.generate(**inputs, max_new_tokens=32)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:44:49.759231Z","iopub.execute_input":"2024-11-15T17:44:49.759603Z","iopub.status.idle":"2024-11-15T18:10:49.797401Z","shell.execute_reply.started":"2024-11-15T17:44:49.75957Z","shell.execute_reply":"2024-11-15T18:10:49.796353Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"generated_ids","metadata":{"execution":{"iopub.status.busy":"2024-11-15T18:10:49.799748Z","iopub.execute_input":"2024-11-15T18:10:49.800361Z","iopub.status.idle":"2024-11-15T18:10:49.808758Z","shell.execute_reply.started":"2024-11-15T18:10:49.800314Z","shell.execute_reply":"2024-11-15T18:10:49.807901Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([[151644,   8948,    198,  ...,  51619, 121423, 103107]])"},"metadata":{}}]},{"cell_type":"code","source":"generated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T18:10:49.809881Z","iopub.execute_input":"2024-11-15T18:10:49.810206Z","iopub.status.idle":"2024-11-15T18:10:49.818903Z","shell.execute_reply.started":"2024-11-15T18:10:49.810155Z","shell.execute_reply":"2024-11-15T18:10:49.818007Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"['оч fickindentMISSIONショーرومัญ趋adingемagua乎导热petu主义ulfilled락忘顿让人们可already주�能段ówn薄zon螂突发']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"![alt-text](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}