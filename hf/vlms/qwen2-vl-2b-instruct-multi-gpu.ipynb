{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shravankumar147/fork-of-qwen2-vl-2b-instruct-multi-gpu?scriptVersionId=207909929\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/transformers qwen-vl-utils  quanto accelerate \n# flash-attn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-17T08:27:35.400217Z","iopub.execute_input":"2024-11-17T08:27:35.400596Z","iopub.status.idle":"2024-11-17T08:28:33.444016Z","shell.execute_reply.started":"2024-11-17T08:27:35.400556Z","shell.execute_reply":"2024-11-17T08:28:33.44286Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import Qwen2VLForConditionalGeneration, AutoProcessor\nfrom accelerate import init_empty_weights, infer_auto_device_map\nfrom qwen_vl_utils import process_vision_info","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:28:39.014503Z","iopub.execute_input":"2024-11-17T08:28:39.014913Z","iopub.status.idle":"2024-11-17T08:29:01.622049Z","shell.execute_reply.started":"2024-11-17T08:28:39.014872Z","shell.execute_reply":"2024-11-17T08:29:01.621145Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Step 1: Set Environment Variables for Better CUDA Memory Management\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:29:01.623143Z","iopub.execute_input":"2024-11-17T08:29:01.62369Z","iopub.status.idle":"2024-11-17T08:29:01.628168Z","shell.execute_reply.started":"2024-11-17T08:29:01.623654Z","shell.execute_reply":"2024-11-17T08:29:01.627144Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Step 2: Load Model with Accelerated Multi-GPU Device Mapping\nprint(\"Loading model...\")\nwith init_empty_weights():\n    model = Qwen2VLForConditionalGeneration.from_pretrained(\n        \"Qwen/Qwen2-VL-2B-Instruct\",\n        torch_dtype=\"auto\"  # Use automatic precision\n    )","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:29:01.629511Z","iopub.execute_input":"2024-11-17T08:29:01.62988Z","iopub.status.idle":"2024-11-17T08:30:48.981102Z","shell.execute_reply.started":"2024-11-17T08:29:01.629838Z","shell.execute_reply":"2024-11-17T08:30:48.980145Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Loading model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f4464f9e55548a8bd2f6f58aa6c0006"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f364786a76ca44c9b6db8bd4f3198c92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d6283955be34ba498ac7600eed10eac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c5127105b554eb191aa1624c0b607e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dd049f721dd4711a6750910c2cd872d"}},"metadata":{}},{"name":"stderr","text":"`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0f1bb542c864b77ac6251d510df7e72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851ca4063a42439f91870b8fad26a2df"}},"metadata":{}}]},{"cell_type":"code","source":"device_map = infer_auto_device_map(\n    model, max_memory={0: \"7GiB\", 1: \"7GiB\", \"cpu\": \"15GiB\"}\n)\nmodel = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-2B-Instruct\",\n    device_map=device_map,\n    torch_dtype=torch.bfloat16,  # Use memory-efficient bfloat16 precision\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:30:55.711412Z","iopub.execute_input":"2024-11-17T08:30:55.712351Z","iopub.status.idle":"2024-11-17T08:30:58.512283Z","shell.execute_reply.started":"2024-11-17T08:30:55.712286Z","shell.execute_reply":"2024-11-17T08:30:58.511451Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59dc3fdb8a4f4fa5a085963db1fea6cf"}},"metadata":{}}]},{"cell_type":"code","source":"# Step 3: Load Processor and Configure Image Token Range\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", min_pixels=256*28*28, max_pixels=1024*28*28)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:30:59.891903Z","iopub.execute_input":"2024-11-17T08:30:59.892301Z","iopub.status.idle":"2024-11-17T08:31:02.332672Z","shell.execute_reply.started":"2024-11-17T08:30:59.892262Z","shell.execute_reply":"2024-11-17T08:31:02.331855Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa3cde4769204812886707b4f7ea7397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"742bc76850004817909e0c497297e3e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"794892bc12f14ee3ac0b886247f5ff28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c780dc31288e4fe99c76ecfe28fe49fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"092c9547f4f74fce9f6a641947e56e0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ffd377dacd649cebd3272875903f000"}},"metadata":{}}]},{"cell_type":"code","source":"# input_image_url = \"https://www.mercedes-benz.co.in/content/india/en/passengercars/models/suv/x296-24-1/overview/_jcr_content/root/responsivegrid/tabs/tabitem/hotspot_module/hotspot_simple_image.component.damq5.3432630554423.jpg/mercedes-benz-eqs-suv-x296-exterior-hotspot-start-3302x1858-02-2024.jpg\"\n# input_image_url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\ninput_image_url = \"https://t4.ftcdn.net/jpg/09/22/14/31/360_F_922143188_z2PQRcdhGUUGogaEPPVGqUu6Qz90KYlA.jpg\"\n# Step 4: Prepare Inputs\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"image\",\n                \"image\": input_image_url,\n            },\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\n\n# Process text and images\ntext = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\"\n)\n# \n# Send inputs to primary GPU\ninputs = inputs.to(\"cuda:0\")\n\n# Step 5: Generate Outputs\nprint(\"Generating outputs...\")\ntry:\n    generated_ids = model.generate(**inputs, max_new_tokens=128)\n    generated_ids_trimmed = [\n        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n    ]\n    output_text = processor.batch_decode(\n        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n    )\n    print(\"Output:\", output_text)\nexcept torch.cuda.OutOfMemoryError as e:\n    print(\"CUDA Out of Memory Error:\", e)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:37:35.830895Z","iopub.execute_input":"2024-11-17T08:37:35.831528Z","iopub.status.idle":"2024-11-17T08:37:41.160982Z","shell.execute_reply.started":"2024-11-17T08:37:35.831484Z","shell.execute_reply":"2024-11-17T08:37:41.160033Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Generating outputs...\nOutput: ['The image depicts a serene and tranquil scene of a person sitting on a wooden dock at the edge of a calm lake. The dock extends into the water, creating a connection between the man and the lake. The lake is surrounded by a misty, mountainous landscape with autumn-colored trees on the shore. The sky above is a gradient of blue hues, suggesting either dawn or dusk. The overall atmosphere is peaceful and contemplative, evoking a sense of solitude and introspection.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"![alt-text](https://t4.ftcdn.net/jpg/09/22/14/31/360_F_922143188_z2PQRcdhGUUGogaEPPVGqUu6Qz90KYlA.jpg)","metadata":{}},{"cell_type":"code","source":"# Step 6: Monitor GPU Usage (Optional)\nprint(\"GPU Usage:\")\nos.system(\"nvidia-smi\")","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:38:28.362487Z","iopub.execute_input":"2024-11-17T08:38:28.362884Z","iopub.status.idle":"2024-11-17T08:38:28.468489Z","shell.execute_reply.started":"2024-11-17T08:38:28.362845Z","shell.execute_reply":"2024-11-17T08:38:28.467577Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"GPU Usage:\nSun Nov 17 08:38:28 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   77C    P0             32W /   70W |    5579MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   50C    P8             10W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]}]}