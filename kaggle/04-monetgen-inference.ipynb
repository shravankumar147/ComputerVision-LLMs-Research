{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Now that your CycleGAN model has been trained, you can use it to generate Monet-style images from photos in the specified directory. The process involves the following steps:\n\n1. **Load the Trained Generator Model**: Load the trained model that translates photos to Monet-style paintings.\n2. **Process the Photos**: Load and preprocess the photos from the given path.\n3. **Generate Monet-Style Images**: Use the generator to convert the photos.\n4. **Save the Outputs**: Save the generated images to a specified directory.\n5. **Create a .zip File**: Compress the directory into a .zip file for easy download.","metadata":{}},{"cell_type":"markdown","source":"Let's walk through these steps with detailed explanations and code.\n\n### Step 1: Load the Trained Generator Model\n\nAssume that you have trained and saved your generator model. Hereâ€™s how you can load it:","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nimport shutil\n\n# Define the Generator model class\nclass Generator(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(Generator, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=7, stride=1, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True)\n        )\n        self.res_blocks = nn.Sequential(\n            *[ResidualBlock(256) for _ in range(6)]\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, out_channels, kernel_size=7, stride=1, padding=3),\n            nn.Tanh()\n        )\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.res_blocks(x)\n        x = self.decoder(x)\n        return x\n\n# Residual Block class\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(in_channels)\n        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(in_channels)\n\n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += residual\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-06-23T05:59:39.524288Z","iopub.execute_input":"2024-06-23T05:59:39.525219Z","iopub.status.idle":"2024-06-23T05:59:39.539685Z","shell.execute_reply.started":"2024-06-23T05:59:39.525186Z","shell.execute_reply":"2024-06-23T05:59:39.538733Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load the trained model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nG_XtoY = Generator(in_channels=3, out_channels=3).to(device)\nG_XtoY.load_state_dict(torch.load('/kaggle/input/monetgen/pytorch/monetgen_v1/1/G_XtoY.pth'))\nG_XtoY.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T05:52:42.851693Z","iopub.execute_input":"2024-06-23T05:52:42.852050Z","iopub.status.idle":"2024-06-23T05:52:49.108186Z","shell.execute_reply.started":"2024-06-23T05:52:42.852018Z","shell.execute_reply":"2024-06-23T05:52:49.107211Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"Generator(\n  (encoder): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n  )\n  (res_blocks): Sequential(\n    (0): ResidualBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): ResidualBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): ResidualBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): ResidualBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): ResidualBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): ResidualBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (decoder): Sequential(\n    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n    (7): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Step 2: Process the Photos\n\nLoad and preprocess the photos to match the input format expected by the generator.","metadata":{}},{"cell_type":"code","source":"import os\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\n\n# Path to the directory containing photos\nphotos_path = \"/kaggle/input/gan-getting-started/photo_jpg\"\n\n# Define the image transformation\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Load and preprocess photos\nphoto_filenames = [f for f in os.listdir(photos_path) if f.endswith('.jpg')]\nphotos = []\nfor filename in photo_filenames:\n    image = Image.open(os.path.join(photos_path, filename)).convert('RGB')\n    image = transform(image)\n    photos.append(image)\n\nphotos = torch.stack(photos)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-23T05:54:11.253563Z","iopub.execute_input":"2024-06-23T05:54:11.254077Z","iopub.status.idle":"2024-06-23T05:54:48.030338Z","shell.execute_reply.started":"2024-06-23T05:54:11.254046Z","shell.execute_reply":"2024-06-23T05:54:48.029135Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"photos[:5].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-23T05:55:34.297615Z","iopub.execute_input":"2024-06-23T05:55:34.298330Z","iopub.status.idle":"2024-06-23T05:55:34.304480Z","shell.execute_reply.started":"2024-06-23T05:55:34.298296Z","shell.execute_reply":"2024-06-23T05:55:34.303529Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"torch.Size([5, 3, 256, 256])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Step 3: Generate Monet-Style Images\n\nUse the loaded generator model to convert the photos to Monet-style paintings.\n\n\n#### Requirements from the competetion:\n\n**Submission File** \n    You are going to generate 7,000-10,000 Monet-style images that are in jpg format. Their sizes should be 256x256x3 (RGB). Then you need to zip those images and your output from your Kernel should only have ONE output file named images.zip.","metadata":{}},{"cell_type":"code","source":"# Directory to save the output images\noutput_dir = '/images'\nos.makedirs(output_dir, exist_ok=True)\n\n# Generate Monet-style images\nwith torch.no_grad():\n    for i, photo in enumerate(photos):\n        photo = photo.unsqueeze(0).to(device)  # Add batch dimension\n        monet_style_image = G_XtoY(photo)\n        monet_style_image = monet_style_image.squeeze(0).cpu()  # Remove batch dimension\n\n        # Convert tensor to PIL Image and denormalize\n        monet_style_image = transforms.ToPILImage()(monet_style_image * 0.5 + 0.5)\n        monet_style_image.save(os.path.join(output_dir, f'monet_style_{i+1}.jpg'))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-23T05:59:47.822565Z","iopub.execute_input":"2024-06-23T05:59:47.823160Z","iopub.status.idle":"2024-06-23T06:01:13.566281Z","shell.execute_reply.started":"2024-06-23T05:59:47.823115Z","shell.execute_reply":"2024-06-23T06:01:13.565463Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Step 4: Create a .zip File\n\nZip the output directory containing the Monet-style images.","metadata":{}},{"cell_type":"code","source":"import shutil","metadata":{"execution":{"iopub.status.busy":"2024-06-23T06:01:52.576246Z","iopub.execute_input":"2024-06-23T06:01:52.576712Z","iopub.status.idle":"2024-06-23T06:01:56.093748Z","shell.execute_reply.started":"2024-06-23T06:01:52.576679Z","shell.execute_reply":"2024-06-23T06:01:56.092803Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Generated Monet-style images and created a zip file successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"output_dir","metadata":{"execution":{"iopub.status.busy":"2024-06-23T06:13:57.651366Z","iopub.execute_input":"2024-06-23T06:13:57.651796Z","iopub.status.idle":"2024-06-23T06:13:57.658526Z","shell.execute_reply.started":"2024-06-23T06:13:57.651728Z","shell.execute_reply":"2024-06-23T06:13:57.657483Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'/images'"},"metadata":{}}]},{"cell_type":"code","source":"# Make Zipfile\nshutil.make_archive(\"/kaggle/working/images\", 'zip', output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T06:15:31.631609Z","iopub.execute_input":"2024-06-23T06:15:31.631981Z","iopub.status.idle":"2024-06-23T06:15:35.236456Z","shell.execute_reply.started":"2024-06-23T06:15:31.631951Z","shell.execute_reply":"2024-06-23T06:15:35.235501Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/images.zip'"},"metadata":{}}]},{"cell_type":"code","source":"\nprint(\"Generated Monet-style images and created a zip file successfully.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete Origin file\nshutil.rmtree(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T06:16:10.325220Z","iopub.execute_input":"2024-06-23T06:16:10.325604Z","iopub.status.idle":"2024-06-23T06:16:10.584068Z","shell.execute_reply.started":"2024-06-23T06:16:10.325564Z","shell.execute_reply":"2024-06-23T06:16:10.583241Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"This code will process the photos, generate Monet-style images, save them in the specified directory, and create a .zip file of the output directory. You can now easily download the .zip file and share the results.","metadata":{}}]}