{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shravankumar147/03-hf-chain-parser?scriptVersionId=214964499\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# First, install required packages:\n!pip install langchain langchain-community langchain-core langchain_huggingface transformers torch pypdf accelerate --upgrade --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-27T05:58:29.140042Z","iopub.execute_input":"2024-12-27T05:58:29.140349Z","iopub.status.idle":"2024-12-27T06:01:28.048834Z","shell.execute_reply.started":"2024-12-27T05:58:29.140324Z","shell.execute_reply":"2024-12-27T06:01:28.04797Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.7/325.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.1 which is incompatible.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\ntorchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n# from langchain_community.llms import HuggingFacePipeline\nfrom langchain_huggingface.llms import HuggingFacePipeline\nfrom langchain_core.prompts import ChatPromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:01:28.050199Z","iopub.execute_input":"2024-12-27T06:01:28.050489Z","iopub.status.idle":"2024-12-27T06:01:40.837923Z","shell.execute_reply.started":"2024-12-27T06:01:28.050461Z","shell.execute_reply":"2024-12-27T06:01:40.837248Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"notebook_login()\n\n# Kaggle Approach to login\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# secret_value_0 = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:01:40.839133Z","iopub.execute_input":"2024-12-27T06:01:40.839714Z","iopub.status.idle":"2024-12-27T06:01:40.858327Z","shell.execute_reply.started":"2024-12-27T06:01:40.83969Z","shell.execute_reply":"2024-12-27T06:01:40.857433Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81eb904ddb0c4a0888f8aded7f84e23e"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\nmodel = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\ntask = \"text-generation\"\n\npipe = pipeline(\n    task,\n    model=model,\n    tokenizer=tokenizer,\n    max_length=1024,\n    temperature=0.3,\n    top_p=0.85,\n    repetition_penalty=1.1,\n    do_sample=True,\n    num_return_sequences=1,\n    pad_token_id=tokenizer.eos_token_id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:03:28.12376Z","iopub.execute_input":"2024-12-27T06:03:28.124119Z","iopub.status.idle":"2024-12-27T06:06:16.231209Z","shell.execute_reply.started":"2024-12-27T06:03:28.12409Z","shell.execute_reply":"2024-12-27T06:06:16.2303Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d1ffdbe7d944a3805ae10003f56a20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af33a2383224b71aedc603af82c92c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b2eee8a9edb4f898bd472beedec6ed1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8ca22dda8f444e08516ae3dec915650"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb612ba47fdd4f89a880c23907f84d45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b1dc43f41f94862b03689eea9b1b75a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74376c6a35f94b19a33826d57336e5b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d0dbce42cdb4a1da6a4f2886d06a54f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b499a64de774598917b332839b84996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac32175d437a4693a2c043b27da46ffb"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=pipe)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:06:44.78452Z","iopub.execute_input":"2024-12-27T06:06:44.784825Z","iopub.status.idle":"2024-12-27T06:06:44.788621Z","shell.execute_reply.started":"2024-12-27T06:06:44.7848Z","shell.execute_reply":"2024-12-27T06:06:44.787715Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"system_prompt = \"\"\"You are tasked with parsing a resume. Your objective is to extract relevant information in a valid structured 'JSON' format. Do not write explanations or any other preambles, do not add or write anything out of context, use only the given information\"\"\"\n\nhuman_prompt = \"\"\"\n             **Task:** Extract key information from the following resume text.\n\n            **Resume Text:**\n            {context}\n\n            **Instructions:**\n            Please extract the following information and format it in a clear structure:\n\n            1. **Contact Information:**\n            - Name:\n            - Email:\n            - Phone Number:\n            - Website/Portfolio/LinkedIn:\n            - Github Profile:\n\n            2. **Education:**\n            - Institution Name:\n            - Degree:\n            - Field of Study:\n            - Graduation Date:\n\n            3. **Experience:**\n            - Job Title:\n            - Company Name:\n            - Location:\n            - Dates of Employment:\n            - Responsibilities/Projects:\n\n            4. **Projects:**\n            - Project Title:\n            - Description/Technologies Used:\n            - Outcomes/Results:\n\n            5. **Skills:**\n            - Programming Languages:\n            - Technologies/Tools/frameworks:\n\n            6. **Additional Information:** (if applicable)\n            - Certifications:\n            - Awards or Honors:\n            - Professional Affiliations:\n            - Languages:\n\n            **Question:**\n            {question}\n\n            **Extracted Information:**\n        \"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:06:46.801202Z","iopub.execute_input":"2024-12-27T06:06:46.801498Z","iopub.status.idle":"2024-12-27T06:06:46.805654Z","shell.execute_reply.started":"2024-12-27T06:06:46.801474Z","shell.execute_reply":"2024-12-27T06:06:46.8047Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"context = \"\"\"Bharath Kumar Parunandula\\n+ Hyderabad\\n# bharathkumar1011@gmail.com\\n\\x84 8639078566\\nð bharathkumar parunandula\\n§ Bharathkumar1011\\nWelcome\\nTo secure an entry-level position as a Junior Data Analyst or Data Scientist, where I can apply my skills in data analysis\\nand visualization to contribute to organizational success while continuously developing my expertise. .\\nPROJECTS\\n• House Prices - Advanced Regression Techniques\\n• Titanic - Machine Learning from Disaster\\n• Iris dataset\\n• Air Quality Index\\nCirtificate\\n• Programming for Everybody\\n• Using Databases with Python\\nEducation\\nB.tech\\nInstitute of Aeronautical Engineering,Aeronautical Engineering\\nGPA: 6.18/10\\n2014 - 2018\\nSkills\\n• Programming Languages: Python, SQLite\\n• Data Analysis: Statistical analysis, data cleaning, and data visualization\\n• Tools and Software: Excel, VS code\\n• Machine Learning: Linear regression, decision trees, and clustering\\n• Database Management: SQLite\\n• Technical Skills: ETL processes, Exploratory Data Analysis (EDA)\\n• Soft Skills: Deep Thinking, teamwork, communication, and attention to detail\\nBooks\\n• The Alchemist\\nbharath kumar parunandula - Page 1 of 1\\nLast updated in September 2024\\n\"\"\"\nquestion = \"Extract key information from this resume.\"\ntemplate = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system_prompt),\n        (\"human\", human_prompt),\n    ]\n)\n\ncomplete_prompt = template.format_messages(context=context, question=question)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:06:48.15361Z","iopub.execute_input":"2024-12-27T06:06:48.153911Z","iopub.status.idle":"2024-12-27T06:06:48.158849Z","shell.execute_reply.started":"2024-12-27T06:06:48.153887Z","shell.execute_reply":"2024-12-27T06:06:48.158178Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(complete_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:06:56.283908Z","iopub.execute_input":"2024-12-27T06:06:56.284281Z","iopub.status.idle":"2024-12-27T06:06:56.290138Z","shell.execute_reply.started":"2024-12-27T06:06:56.284253Z","shell.execute_reply":"2024-12-27T06:06:56.289234Z"}},"outputs":[{"name":"stdout","text":"[SystemMessage(content=\"You are tasked with parsing a resume. Your objective is to extract relevant information in a valid structured 'JSON' format. Do not write explanations or any other preambles, do not add or write anything out of context, use only the given information\", additional_kwargs={}, response_metadata={}), HumanMessage(content='\\n             **Task:** Extract key information from the following resume text.\\n\\n            **Resume Text:**\\n            Bharath Kumar Parunandula\\n+ Hyderabad\\n# bharathkumar1011@gmail.com\\n\\x84 8639078566\\nð bharathkumar parunandula\\n§ Bharathkumar1011\\nWelcome\\nTo secure an entry-level position as a Junior Data Analyst or Data Scientist, where I can apply my skills in data analysis\\nand visualization to contribute to organizational success while continuously developing my expertise. .\\nPROJECTS\\n• House Prices - Advanced Regression Techniques\\n• Titanic - Machine Learning from Disaster\\n• Iris dataset\\n• Air Quality Index\\nCirtificate\\n• Programming for Everybody\\n• Using Databases with Python\\nEducation\\nB.tech\\nInstitute of Aeronautical Engineering,Aeronautical Engineering\\nGPA: 6.18/10\\n2014 - 2018\\nSkills\\n• Programming Languages: Python, SQLite\\n• Data Analysis: Statistical analysis, data cleaning, and data visualization\\n• Tools and Software: Excel, VS code\\n• Machine Learning: Linear regression, decision trees, and clustering\\n• Database Management: SQLite\\n• Technical Skills: ETL processes, Exploratory Data Analysis (EDA)\\n• Soft Skills: Deep Thinking, teamwork, communication, and attention to detail\\nBooks\\n• The Alchemist\\nbharath kumar parunandula - Page 1 of 1\\nLast updated in September 2024\\n\\n\\n            **Instructions:**\\n            Please extract the following information and format it in a clear structure:\\n\\n            1. **Contact Information:**\\n            - Name:\\n            - Email:\\n            - Phone Number:\\n            - Website/Portfolio/LinkedIn:\\n            - Github Profile:\\n\\n            2. **Education:**\\n            - Institution Name:\\n            - Degree:\\n            - Field of Study:\\n            - Graduation Date:\\n\\n            3. **Experience:**\\n            - Job Title:\\n            - Company Name:\\n            - Location:\\n            - Dates of Employment:\\n            - Responsibilities/Projects:\\n\\n            4. **Projects:**\\n            - Project Title:\\n            - Description/Technologies Used:\\n            - Outcomes/Results:\\n\\n            5. **Skills:**\\n            - Programming Languages:\\n            - Technologies/Tools/frameworks:\\n\\n            6. **Additional Information:** (if applicable)\\n            - Certifications:\\n            - Awards or Honors:\\n            - Professional Affiliations:\\n            - Languages:\\n\\n            **Question:**\\n            Extract key information from this resume.\\n\\n            **Extracted Information:**\\n        ', additional_kwargs={}, response_metadata={})]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%time\nresponse = llm.invoke(complete_prompt, skip_prompt=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:06:57.471545Z","iopub.execute_input":"2024-12-27T06:06:57.471848Z","iopub.status.idle":"2024-12-27T06:07:14.360247Z","shell.execute_reply.started":"2024-12-27T06:06:57.471823Z","shell.execute_reply":"2024-12-27T06:07:14.3595Z"}},"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 15.6 s, sys: 84.3 ms, total: 15.6 s\nWall time: 16.9 s\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T06:07:14.361193Z","iopub.execute_input":"2024-12-27T06:07:14.361498Z","iopub.status.idle":"2024-12-27T06:07:14.365314Z","shell.execute_reply.started":"2024-12-27T06:07:14.36145Z","shell.execute_reply":"2024-12-27T06:07:14.364606Z"}},"outputs":[{"name":"stdout","text":" {\n          \"Name\": \"Bharath Kumar Parunandula\",\n          \"Contact Information\": {\n            \"Email\": \"+ bharathkumar1011@gmail.com\",\n            \"Phone Number\": \"8639078566\",\n            \"Website/Portfolio/LinkedIn\": \"\",\n            \"Github Profile\": \"\"\n          },\n          \"Education\": {\n            \"Institution Name\": \"Institute of Aeronautical Engineering\",\n            \"Degree\": \"B.tech\",\n            \"Field of Study\": \"Aeronautical Engineering\",\n            \"Graduation Date\": \"2014-2018\"\n          },\n          \"Projects\": [\n            {\n              \"Project Title\": \"House Prices - Advanced Regression Techniques\",\n              \"Description/Technologies Used\": \"Advanced Regression Techniques\",\n              \"Outcomes/Results\": null\n            },\n            {\n              \"Project Title\": \"Titanic - Machine Learning from Disaster\",\n              \"Description/Technologies Used\": \"Machine Learning from Disaster\",\n              \"Outcomes/Results\": null\n            },\n            {\n              \"Project Title\": \"Iris dataset\",\n              \"Description/Technologies Used\": \"Iris dataset\",\n              \"Outcomes/Results\": null\n            },\n            {\n              \"Project Title\": \"Air Quality Index\",\n              \"Description/Technologies Used\": \"Air Quality Index\",\n              \"Outcomes/Results\": null\n            }\n          ],\n          \"Skills\": {\n            \"Programming Languages\": [\"Python\", \"SQLite\"],\n            \"Technologies/Tools/frameworks\": [\"Excel\", \"VS code\"]\n          },\n          \"Additional Information\": {\n            \"Certifications\": [\"Programming for Everybody\", \"Using Databases with Python\"],\n            \"Languages\": []\n          }\n        } \n\nNote: The extracted information was formatted according to the provided instructions.\n","output_type":"stream"}],"execution_count":11}]}