{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shravankumar147/hugging-face-models-with-langchain-for-resume-data?scriptVersionId=214450951\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Integrating Hugging Face Models with LangChain for Resume Data Extraction","metadata":{}},{"cell_type":"code","source":"!pip install transformers langchain-core","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T13:20:12.456843Z","iopub.execute_input":"2024-12-23T13:20:12.457192Z","iopub.status.idle":"2024-12-23T13:20:21.748591Z","shell.execute_reply.started":"2024-12-23T13:20:12.45715Z","shell.execute_reply":"2024-12-23T13:20:21.747324Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nCollecting langchain-core\n  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nCollecting jsonpatch<2.0,>=1.33 (from langchain-core)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting langsmith<0.3,>=0.1.125 (from langchain-core)\n  Downloading langsmith-0.2.4-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.9.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (9.0.0)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\nCollecting httpx<1,>=0.23.0 (from langsmith<0.3,>=0.1.125->langchain-core)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.125->langchain-core)\n  Downloading orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.125->langchain-core)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core) (3.7.1)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core)\n  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\nCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core)\n  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core) (1.2.2)\nDownloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langsmith-0.2.4-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: orjson, jsonpatch, h11, requests-toolbelt, httpcore, httpx, langsmith, langchain-core\nSuccessfully installed h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jsonpatch-1.33 langchain-core-0.3.28 langsmith-0.2.4 orjson-3.10.12 requests-toolbelt-1.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import pipeline\nfrom langchain_core.prompts import (\n    SystemMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n    ChatPromptTemplate,\n)\nfrom langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n\n# Load a Hugging Face model using the pipeline\nmodel_name = \"tiiuae/falcon-7b-instruct\"  # Replace with your desired Hugging Face model\nllm = pipeline(\"text2text-generation\", model=model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T13:21:11.329822Z","iopub.execute_input":"2024-12-23T13:21:11.330284Z","iopub.status.idle":"2024-12-23T13:24:20.6307Z","shell.execute_reply.started":"2024-12-23T13:21:11.330249Z","shell.execute_reply":"2024-12-23T13:24:20.628789Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01b9134adc804b89b47e43c762a9546d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/17.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a61583a39d74460cac6a95c6172b70bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec4f935635294a868ef0fcb54f239129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f58af96fd9554396b7197aed59d85154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed9beebedff44d329ff2778dd0a660b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faa4003f92cc48fb874ea0292dd3580b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"590f51efa6eb4e47aa9d929ab1ead1cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a5199902b5f48a398a3f0e0d16c2fd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3465dd1a0c14d22a2e243149d1584a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39a22f9e142745548a80f856b901f7e4"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nThe model 'FalconForCausalLM' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# System Message\nsystem_message_prompt = SystemMessagePromptTemplate.from_template(\n    \"\"\"You are a helpful AI assistant who answers user's questions based on the provided context\"\"\"\n)\n\n# Prompt Template\nprompt = \"\"\"\n            **Task:** Extract key information from the following resume text.\n\n            **Resume Text:**\n            {context}\n\n            **Instructions:**\n            Please extract the following information and format it in a clear structure:\n\n            1. **Contact Information:**\n            - Name:\n            - Email:\n            - Phone Number:\n            - Website/Portfolio/LinkedIn:\n            - Github Profile:\n\n            2. **Education:**\n            - Institution Name:\n            - Degree:\n            - Field of Study:\n            - Graduation Date:\n\n            3. **Experience:**\n            - Job Title:\n            - Company Name:\n            - Location:\n            - Dates of Employment:\n            - Responsibilities/Projects:\n\n            4. **Projects:**\n            - Project Title:\n            - Description/Technologies Used:\n            - Outcomes/Results:\n\n            5. **Skills:**\n            - Programming Languages:\n            - Technologies/Tools/frameworks:\n\n            6. **Additional Information:** (if applicable)\n            - Certifications:\n            - Awards or Honors:\n            - Professional Affiliations:\n            - Languages:\n\n            **Question:**\n            {question}\n\n            **Extracted Information:**\n        \"\"\"\n\nhuman_message_prompt = HumanMessagePromptTemplate.from_template(prompt)\n\n# Define a function to call the model\ndef LLM_chain(context, question):\n    template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n    complete_prompt = template.format_messages({\"context\": context, \"question\": question})[1].content\n    response = llm(complete_prompt, max_length=500)[0]['generated_text']\n    return response\n\n# JSON Validation Chain\ndef LLM_chain_json(context):\n    json_prompt_validate = \"\"\"\n            **Task:** Validate and correct the following JSON data:\n\n            **JSON Data:**\n            {context}\n\n            **Instructions:**\n            Provide JSON-only output with no explanation or preamble.\n\n            **Corrected JSON:**\"\"\"\n    human_message = HumanMessagePromptTemplate.from_template(json_prompt_validate)\n    template = ChatPromptTemplate.from_messages([system_message_prompt, human_message])\n    complete_prompt = template.format_messages({\"context\": context})[1].content\n    response = llm(complete_prompt, max_length=500)[0]['generated_text']\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T13:24:57.607511Z","iopub.execute_input":"2024-12-23T13:24:57.608678Z","iopub.status.idle":"2024-12-23T13:24:57.622814Z","shell.execute_reply.started":"2024-12-23T13:24:57.608614Z","shell.execute_reply":"2024-12-23T13:24:57.621103Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# !pip install transformers langchain-core\n\nfrom transformers import pipeline\nfrom langchain_core.prompts import (\n    SystemMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n    ChatPromptTemplate,\n)\nfrom langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n\n# Load a Hugging Face model\nmodel_name = \"tiiuae/falcon-7b-instruct\"  # Choose an appropriate model\nllm = pipeline(\"text2text-generation\", model=model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T13:26:33.944891Z","iopub.execute_input":"2024-12-23T13:26:33.945277Z","iopub.status.idle":"2024-12-23T13:26:34.402541Z","shell.execute_reply.started":"2024-12-23T13:26:33.94525Z","shell.execute_reply":"2024-12-23T13:26:34.4009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prompt Templates\nsystem_message_prompt = SystemMessagePromptTemplate.from_template(\n    \"\"\"You are a helpful AI assistant who answers user's questions based on the provided context\"\"\"\n)\nprompt = \"\"\"\n**Task:** Extract key information from the following resume text.\n\n**Resume Text:**\n{context}\n\n**Instructions:**\nPlease extract the following information and format it in a clear structure:\n\n1. **Contact Information:**\n- Name:\n- Email:\n- Phone Number:\n- Website/Portfolio/LinkedIn:\n- Github Profile:\n\n2. **Education:**\n- Institution Name:\n- Degree:\n- Field of Study:\n- Graduation Date:\n\n3. **Experience:**\n- Job Title:\n- Company Name:\n- Location:\n- Dates of Employment:\n- Responsibilities/Projects:\n\n4. **Projects:**\n- Project Title:\n- Description/Technologies Used:\n- Outcomes/Results:\n\n5. **Skills:**\n- Programming Languages:\n- Technologies/Tools/frameworks:\n\n**Question:**\n{question}\n\n**Extracted Information:**\n\"\"\"\nhuman_message_prompt = HumanMessagePromptTemplate.from_template(prompt)\n\ndef LLM_chain(context, question):\n    # Format messages using keyword arguments\n    template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n    complete_prompt = template.format_messages(context=context, question=question)[1].content\n    response = llm(complete_prompt, max_length=500)[0]['generated_text']\n    return response\n\n\n# Test Data\nresume_text = \"\"\"\nJohn Doe\njohndoe@example.com\n+1 123-456-7890\nlinkedin.com/in/johndoe\ngithub.com/johndoe\n\nEducation:\n- XYZ University, B.Sc. Computer Science, 2015-2019\n\nExperience:\n- Software Engineer at ABC Corp, Jan 2020 - Present\n  Responsibilities: Developed web applications using Python and React.\n\nSkills:\n- Python, JavaScript, React, SQL\n\"\"\"\nquestion = \"Extract key information from this resume.\"\n\n# Run Extraction\nresponse = LLM_chain(resume_text, question)\nprint(\"Extracted Information:\\n\", response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T13:28:17.286539Z","iopub.execute_input":"2024-12-23T13:28:17.286944Z","iopub.status.idle":"2024-12-23T13:32:58.030393Z","shell.execute_reply.started":"2024-12-23T13:28:17.28691Z","shell.execute_reply":"2024-12-23T13:32:58.029202Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Extracted Information:\n \n**Task:** Extract key information from the following resume text.\n\n**Resume Text:**\n\nJohn Doe\njohndoe@example.com\n+1 123-456-7890\nlinkedin.com/in/johndoe\ngithub.com/johndoe\n\nEducation:\n- XYZ University, B.Sc. Computer Science, 2015-2019\n\nExperience:\n- Software Engineer at ABC Corp, Jan 2020 - Present\n  Responsibilities: Developed web applications using Python and React.\n\nSkills:\n- Python, JavaScript, React, SQL\n\n\n**Instructions:**\nPlease extract the following information and format it in a clear structure:\n\n1. **Contact Information:**\n- Name:\n- Email:\n- Phone Number:\n- Website/Portfolio/LinkedIn:\n- Github Profile:\n\n2. **Education:**\n- Institution Name:\n- Degree:\n- Field of Study:\n- Graduation Date:\n\n3. **Experience:**\n- Job Title:\n- Company Name:\n- Location:\n- Dates of Employment:\n- Responsibilities/Projects:\n\n4. **Projects:**\n- Project Title:\n- Description/Technologies Used:\n- Outcomes/Results:\n\n5. **Skills:**\n- Programming Languages:\n- Technologies/Tools/frameworks:\n\n**Question:**\nExtract key information from this resume.\n\n**Extracted Information:**\n- Name: John Doe\n- Email: johndoe@example.com\n- Phone Number: +1 123-456-7890\n- Website/Portfolio/LinkedIn: linkedin.com/in/johndoe\n- Github Profile: github.com/johndoe\n- Education:\n- XYZ University, B.Sc. Computer Science, 2015-2019\n- Experience:\n- Software Engineer at ABC Corp, Jan 2020 - Present\n- Responsibilities: Developed web applications using Python and React.\n- Skills:\n- Python, JavaScript, React, SQL\n\nThe extracted information is:\n- Name: John Doe\n- Email: johndoe@example.com\n- Phone Number: +1 123-456-7890\n- Website/Portfolio/LinkedIn: linked\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}