{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shravankumar147/01-nanogpt?scriptVersionId=186239760\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Building a GPT\n\nCompanion notebook to the [Zero To Hero](https://karpathy.ai/zero-to-hero.html) video on GPT.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T13:01:18.813365Z","iopub.execute_input":"2024-06-30T13:01:18.813752Z","iopub.status.idle":"2024-06-30T13:01:20.540136Z","shell.execute_reply.started":"2024-06-30T13:01:18.813719Z","shell.execute_reply":"2024-06-30T13:01:20.538898Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2024-06-30 13:01:19--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: 'input.txt'\n\ninput.txt           100%[===================>]   1.06M  5.15MB/s    in 0.2s    \n\n2024-06-30 13:01:20 (5.15 MB/s) - 'input.txt' saved [1115394/1115394]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# read it in to inspect it\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()\n\nprint(\"length of dataset in characters: \", len(text))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T13:01:20.542371Z","iopub.execute_input":"2024-06-30T13:01:20.542766Z","iopub.status.idle":"2024-06-30T13:01:20.550317Z","shell.execute_reply.started":"2024-06-30T13:01:20.54273Z","shell.execute_reply":"2024-06-30T13:01:20.549227Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"length of dataset in characters:  1115394\n","output_type":"stream"}]},{"cell_type":"code","source":"# let's look at the first 1000 characters\nprint(text[:1000])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T13:01:20.551998Z","iopub.execute_input":"2024-06-30T13:01:20.552742Z","iopub.status.idle":"2024-06-30T13:01:20.562881Z","shell.execute_reply.started":"2024-06-30T13:01:20.552643Z","shell.execute_reply":"2024-06-30T13:01:20.561713Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T13:01:20.564737Z","iopub.execute_input":"2024-06-30T13:01:20.565045Z","iopub.status.idle":"2024-06-30T13:01:20.592028Z","shell.execute_reply.started":"2024-06-30T13:01:20.565021Z","shell.execute_reply":"2024-06-30T13:01:20.590882Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\n\nstoi = {ch:i for i,ch in enumerate(chars)}\nitos = {i:ch for i,ch in enumerate(chars)}\n\nencode = lambda s: [stoi[c] for c in s]\ndecode = lambda l: \"\".join([itos[i] for i in l])","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:20.59395Z","iopub.execute_input":"2024-06-30T13:01:20.594279Z","iopub.status.idle":"2024-06-30T13:01:20.602437Z","shell.execute_reply.started":"2024-06-30T13:01:20.594253Z","shell.execute_reply":"2024-06-30T13:01:20.601375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(encode(\"hello\"))","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:20.868537Z","iopub.execute_input":"2024-06-30T13:01:20.869234Z","iopub.status.idle":"2024-06-30T13:01:20.874372Z","shell.execute_reply.started":"2024-06-30T13:01:20.8692Z","shell.execute_reply":"2024-06-30T13:01:20.873338Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[46, 43, 50, 50, 53]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(decode(encode(\"hello\")))","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:22.019374Z","iopub.execute_input":"2024-06-30T13:01:22.020116Z","iopub.status.idle":"2024-06-30T13:01:22.02496Z","shell.execute_reply.started":"2024-06-30T13:01:22.020083Z","shell.execute_reply":"2024-06-30T13:01:22.023991Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"hello\n","output_type":"stream"}]},{"cell_type":"code","source":"# let's now encode the entire text dataset and store it into a torch.Tensor\nimport torch\n\nprint(f\"No. of chars: {len(text)}\")\nprint(f\"No. of encoded integers: {len(encode(text))}\") # => 1115394; \nassert len(text)==len(encode(text)) #this confirms our ecoder is working fine\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:22.3908Z","iopub.execute_input":"2024-06-30T13:01:22.391166Z","iopub.status.idle":"2024-06-30T13:01:25.295797Z","shell.execute_reply.started":"2024-06-30T13:01:22.391139Z","shell.execute_reply":"2024-06-30T13:01:25.294659Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"No. of chars: 1115394\nNo. of encoded integers: 1115394\n","output_type":"stream"}]},{"cell_type":"code","source":"encoded_text = encode(text)\ndata = torch.tensor(encoded_text, dtype=torch.long)\n\nprint(data.shape, data.dtype)\n\nprint(data[:1000])","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.297578Z","iopub.execute_input":"2024-06-30T13:01:25.298027Z","iopub.status.idle":"2024-06-30T13:01:25.562518Z","shell.execute_reply.started":"2024-06-30T13:01:25.297999Z","shell.execute_reply":"2024-06-30T13:01:25.561482Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"torch.Size([1115394]) torch.int64\ntensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Let's now split up the data into train and validation sets\n# first 90% will be train, rest val\nprint(f\"Data Size: {len(data)}\")\nn = int(len(data)*0.9)\n\nprint(f\"90%: {len(data[:n])}| 10%: {len(data[n:])}\")\n\nprint(f\"90%: {len(data[:n])} + 10%: {len(data[n:])} =  {len(data[:n]) + len(data[n:])}\")\nassert len(data[:n]) + len(data[n:]) == len(data)\n\n\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.563708Z","iopub.execute_input":"2024-06-30T13:01:25.564092Z","iopub.status.idle":"2024-06-30T13:01:25.571823Z","shell.execute_reply.started":"2024-06-30T13:01:25.564059Z","shell.execute_reply":"2024-06-30T13:01:25.570706Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Data Size: 1115394\n90%: 1003854| 10%: 111540\n90%: 1003854 + 10%: 111540 =  1115394\n","output_type":"stream"}]},{"cell_type":"code","source":"block_size = 8 # also known as context length, that a transformer see\n\ntrain_data[:block_size+1]","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.573792Z","iopub.execute_input":"2024-06-30T13:01:25.574097Z","iopub.status.idle":"2024-06-30T13:01:25.584977Z","shell.execute_reply.started":"2024-06-30T13:01:25.574073Z","shell.execute_reply":"2024-06-30T13:01:25.583816Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\n\nprint(f\"input context-> target\")\nprint(\"=\"*50)\n\nfor t in range(block_size):    \n    print(f\"{x[:t+1]} -> {y[t]}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.586252Z","iopub.execute_input":"2024-06-30T13:01:25.586682Z","iopub.status.idle":"2024-06-30T13:01:25.595475Z","shell.execute_reply.started":"2024-06-30T13:01:25.586631Z","shell.execute_reply":"2024-06-30T13:01:25.594491Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"input context-> target\n==================================================\ntensor([18]) -> 47\ntensor([18, 47]) -> 56\ntensor([18, 47, 56]) -> 57\ntensor([18, 47, 56, 57]) -> 58\ntensor([18, 47, 56, 57, 58]) -> 1\ntensor([18, 47, 56, 57, 58,  1]) -> 15\ntensor([18, 47, 56, 57, 58,  1, 15]) -> 47\ntensor([18, 47, 56, 57, 58,  1, 15, 47]) -> 58\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\n\ndef get_batch(split):\n    data = train_data if split=='train' else val_data\n    \n    # This line generates batch_size random indices (ix) within the range from 0 to len(data) - block_size. \n    # The subtraction by block_size ensures thereâ€™s enough room to create sequences of length block_size.\n    ix = torch.randint(low=0, high=len(data)-block_size, size=(batch_size,)) # we get batch_size random integers within the range\n    \n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    \n    return x,y","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.59708Z","iopub.execute_input":"2024-06-30T13:01:25.597532Z","iopub.status.idle":"2024-06-30T13:01:25.607941Z","shell.execute_reply.started":"2024-06-30T13:01:25.597497Z","shell.execute_reply":"2024-06-30T13:01:25.607009Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"xb, yb = get_batch('train')\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\nprint('----')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.880784Z","iopub.execute_input":"2024-06-30T13:01:25.881475Z","iopub.status.idle":"2024-06-30T13:01:25.912195Z","shell.execute_reply.started":"2024-06-30T13:01:25.881441Z","shell.execute_reply":"2024-06-30T13:01:25.911137Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"inputs:\ntorch.Size([4, 8])\ntensor([[24, 43, 58,  5, 57,  1, 46, 43],\n        [44, 53, 56,  1, 58, 46, 39, 58],\n        [52, 58,  1, 58, 46, 39, 58,  1],\n        [25, 17, 27, 10,  0, 21,  1, 54]])\ntargets:\ntorch.Size([4, 8])\ntensor([[43, 58,  5, 57,  1, 46, 43, 39],\n        [53, 56,  1, 58, 46, 39, 58,  1],\n        [58,  1, 58, 46, 39, 58,  1, 46],\n        [17, 27, 10,  0, 21,  1, 54, 39]])\n----\n","output_type":"stream"}]},{"cell_type":"code","source":"for b in range(batch_size):\n    for t in range(block_size):\n        context = xb[b,:t+1]\n        target = yb[b, t]\n        \n        print(f\"when the input is: {context.tolist()}, the target is: {target}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:26.739472Z","iopub.execute_input":"2024-06-30T13:01:26.74015Z","iopub.status.idle":"2024-06-30T13:01:26.747036Z","shell.execute_reply.started":"2024-06-30T13:01:26.740116Z","shell.execute_reply":"2024-06-30T13:01:26.746026Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"when the input is: [24], the target is: 43\nwhen the input is: [24, 43], the target is: 58\nwhen the input is: [24, 43, 58], the target is: 5\nwhen the input is: [24, 43, 58, 5], the target is: 57\nwhen the input is: [24, 43, 58, 5, 57], the target is: 1\nwhen the input is: [24, 43, 58, 5, 57, 1], the target is: 46\nwhen the input is: [24, 43, 58, 5, 57, 1, 46], the target is: 43\nwhen the input is: [24, 43, 58, 5, 57, 1, 46, 43], the target is: 39\nwhen the input is: [44], the target is: 53\nwhen the input is: [44, 53], the target is: 56\nwhen the input is: [44, 53, 56], the target is: 1\nwhen the input is: [44, 53, 56, 1], the target is: 58\nwhen the input is: [44, 53, 56, 1, 58], the target is: 46\nwhen the input is: [44, 53, 56, 1, 58, 46], the target is: 39\nwhen the input is: [44, 53, 56, 1, 58, 46, 39], the target is: 58\nwhen the input is: [44, 53, 56, 1, 58, 46, 39, 58], the target is: 1\nwhen the input is: [52], the target is: 58\nwhen the input is: [52, 58], the target is: 1\nwhen the input is: [52, 58, 1], the target is: 58\nwhen the input is: [52, 58, 1, 58], the target is: 46\nwhen the input is: [52, 58, 1, 58, 46], the target is: 39\nwhen the input is: [52, 58, 1, 58, 46, 39], the target is: 58\nwhen the input is: [52, 58, 1, 58, 46, 39, 58], the target is: 1\nwhen the input is: [52, 58, 1, 58, 46, 39, 58, 1], the target is: 46\nwhen the input is: [25], the target is: 17\nwhen the input is: [25, 17], the target is: 27\nwhen the input is: [25, 17, 27], the target is: 10\nwhen the input is: [25, 17, 27, 10], the target is: 0\nwhen the input is: [25, 17, 27, 10, 0], the target is: 21\nwhen the input is: [25, 17, 27, 10, 0, 21], the target is: 1\nwhen the input is: [25, 17, 27, 10, 0, 21, 1], the target is: 54\nwhen the input is: [25, 17, 27, 10, 0, 21, 1, 54], the target is: 39\n","output_type":"stream"}]},{"cell_type":"code","source":"print(xb) # our input to the transformer","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:27.404964Z","iopub.execute_input":"2024-06-30T13:01:27.405877Z","iopub.status.idle":"2024-06-30T13:01:27.411556Z","shell.execute_reply.started":"2024-06-30T13:01:27.405842Z","shell.execute_reply":"2024-06-30T13:01:27.410528Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n        [44, 53, 56,  1, 58, 46, 39, 58],\n        [52, 58,  1, 58, 46, 39, 58,  1],\n        [25, 17, 27, 10,  0, 21,  1, 54]])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntorch.manual_seed(1337)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:28.291219Z","iopub.execute_input":"2024-06-30T13:01:28.291901Z","iopub.status.idle":"2024-06-30T13:01:28.299678Z","shell.execute_reply.started":"2024-06-30T13:01:28.291867Z","shell.execute_reply":"2024-06-30T13:01:28.298669Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x79a763a8b2d0>"},"metadata":{}}]},{"cell_type":"code","source":"emb = nn.Embedding(vocab_size, vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:30.103628Z","iopub.execute_input":"2024-06-30T13:01:30.104601Z","iopub.status.idle":"2024-06-30T13:01:30.112187Z","shell.execute_reply.started":"2024-06-30T13:01:30.104563Z","shell.execute_reply":"2024-06-30T13:01:30.111155Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Here we test the Embedding layer","metadata":{}},{"cell_type":"markdown","source":"It accepts a tensor as input","metadata":{}},{"cell_type":"code","source":"print(emb(torch.tensor(0))) # for a 1-d tensor it has generated below output\nprint(emb(torch.tensor(0)).shape) # the shape is 65, which are embeddings from the embedding lookup table","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:32.869502Z","iopub.execute_input":"2024-06-30T13:01:32.870386Z","iopub.status.idle":"2024-06-30T13:01:32.91224Z","shell.execute_reply.started":"2024-06-30T13:01:32.870351Z","shell.execute_reply":"2024-06-30T13:01:32.911277Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"tensor([ 0.1808, -0.0700, -0.3596, -0.9152,  0.6258,  0.0255,  0.9545,  0.0643,\n         0.3612,  1.1679, -1.3499, -0.5102,  0.2360, -0.2398, -0.9211,  1.5433,\n         1.3488, -0.1396,  0.2858,  0.9651, -2.0371,  0.4931,  1.4870,  0.5910,\n         0.1260, -1.5627, -1.1601, -0.3348,  0.4478, -0.8016,  1.5236,  2.5086,\n        -0.6631, -0.2513,  1.0101,  0.1215,  0.1584,  1.1340, -1.1539, -0.2984,\n        -0.5075, -0.9239,  0.5467, -1.4948, -1.2057,  0.5718, -0.5974, -0.6937,\n         1.6455, -0.8030,  1.3514, -0.2759, -1.5108,  2.1048,  2.7630, -1.7465,\n         1.4516, -1.5103,  0.8212, -0.2115,  0.7789,  1.5333,  1.6097, -0.4032,\n        -0.8345], grad_fn=<EmbeddingBackward0>)\ntorch.Size([65])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can pass a batch of input to the embedding layer, so let's pass our xb batch","metadata":{}},{"cell_type":"code","source":"xb.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:34.840386Z","iopub.execute_input":"2024-06-30T13:01:34.841058Z","iopub.status.idle":"2024-06-30T13:01:34.847744Z","shell.execute_reply.started":"2024-06-30T13:01:34.841024Z","shell.execute_reply":"2024-06-30T13:01:34.846312Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 8])"},"metadata":{}}]},{"cell_type":"code","source":"logits = emb(xb)\nB,T,C = logits.shape\nprint(B,T,C)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:35.780405Z","iopub.execute_input":"2024-06-30T13:01:35.780898Z","iopub.status.idle":"2024-06-30T13:01:35.786018Z","shell.execute_reply.started":"2024-06-30T13:01:35.780869Z","shell.execute_reply":"2024-06-30T13:01:35.785116Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"4 8 65\n","output_type":"stream"}]},{"cell_type":"markdown","source":"4 is the batch size\n\n8 is the block size (time-dimention)\n\n65 is the output embedding (channel -dimention)","metadata":{}},{"cell_type":"markdown","source":"Let's do some reshaping - this will come handy when we compute cross-entropy loss for our Bigram model","metadata":{}},{"cell_type":"code","source":"logits.view(B*T, C).shape # using view approach","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:46.496941Z","iopub.execute_input":"2024-06-30T13:01:46.497666Z","iopub.status.idle":"2024-06-30T13:01:46.503945Z","shell.execute_reply.started":"2024-06-30T13:01:46.497617Z","shell.execute_reply":"2024-06-30T13:01:46.502942Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 65])"},"metadata":{}}]},{"cell_type":"code","source":"logits.flatten(start_dim=0, end_dim=1).shape # using flatten approach","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:47.440218Z","iopub.execute_input":"2024-06-30T13:01:47.441105Z","iopub.status.idle":"2024-06-30T13:01:47.447979Z","shell.execute_reply.started":"2024-06-30T13:01:47.441069Z","shell.execute_reply":"2024-06-30T13:01:47.446803Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 65])"},"metadata":{}}]},{"cell_type":"markdown","source":"We can use any method, so I am chosing view, because I can use my pre computed B,T, and C there","metadata":{}},{"cell_type":"code","source":"class BigramLanguageModel(nn.Module):\n    def __init__(self, vocab_size):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n        \n    def forward(self, idx, targets=None):\n        logits = self.token_embedding_table(idx)\n        if targets is None:\n            loss = None\n        else:\n            \n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            \n            loss = F.cross_entropy(logits, targets)\n            \n        return logits, loss\n        \n    def generate(self, idx, max_new_tokens):\n        for _ in range(max_new_tokens):\n            logits, loss = self(idx) # Logits has shape: (B, T, C)\n            \n            # Let's take the last time step from the logits/predictions\n            logits = logits[:,-1,:] #(B, C)\n            \n            # apply softmax to get the probabilities of these predictions\n            # over the Channels dimensions. \n            probs = F.softmax(logits, dim=-1) #(B, C)\n            \n            # torch.multinomial returns a tensor where each row contains num_samples indices \n            # sampled from the multinomial probability distribution located in the corresponding \n            # row of tensor input.\n            \n            idx_next = torch.multinomial(probs, num_samples=1)\n            \n            # add the next probable prediction to the current idx batch.\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n            \n        return idx   \n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-30T14:18:15.945071Z","iopub.execute_input":"2024-06-30T14:18:15.945491Z","iopub.status.idle":"2024-06-30T14:18:15.954842Z","shell.execute_reply.started":"2024-06-30T14:18:15.945459Z","shell.execute_reply":"2024-06-30T14:18:15.953709Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"m = BigramLanguageModel(vocab_size)\nlogits, loss = m(xb, yb)\nprint(logits.shape)\nprint(loss)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T14:18:59.224835Z","iopub.execute_input":"2024-06-30T14:18:59.225807Z","iopub.status.idle":"2024-06-30T14:18:59.236555Z","shell.execute_reply.started":"2024-06-30T14:18:59.225772Z","shell.execute_reply":"2024-06-30T14:18:59.23559Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"torch.Size([32, 65])\ntensor(4.9105, grad_fn=<NllLossBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-30T14:19:13.867788Z","iopub.execute_input":"2024-06-30T14:19:13.868727Z","iopub.status.idle":"2024-06-30T14:19:13.887724Z","shell.execute_reply.started":"2024-06-30T14:19:13.86868Z","shell.execute_reply":"2024-06-30T14:19:13.886665Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"\nxNb:mxaJ:tpmUKk-N.WbOOkFS,HWq--NUpzQqU;ych.Uo$D\nPGuKtbHHwy3!nhEL\n3fm&;NDcZytNUIT v tYzAYrMr$CCa!oNic\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}