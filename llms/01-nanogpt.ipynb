{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shravankumar147/01-nanogpt?scriptVersionId=186236545\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Building a GPT\n\nCompanion notebook to the [Zero To Hero](https://karpathy.ai/zero-to-hero.html) video on GPT.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T13:01:18.813365Z","iopub.execute_input":"2024-06-30T13:01:18.813752Z","iopub.status.idle":"2024-06-30T13:01:20.540136Z","shell.execute_reply.started":"2024-06-30T13:01:18.813719Z","shell.execute_reply":"2024-06-30T13:01:20.538898Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2024-06-30 13:01:19--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: 'input.txt'\n\ninput.txt           100%[===================>]   1.06M  5.15MB/s    in 0.2s    \n\n2024-06-30 13:01:20 (5.15 MB/s) - 'input.txt' saved [1115394/1115394]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# read it in to inspect it\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()\n\nprint(\"length of dataset in characters: \", len(text))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T13:01:20.542371Z","iopub.execute_input":"2024-06-30T13:01:20.542766Z","iopub.status.idle":"2024-06-30T13:01:20.550317Z","shell.execute_reply.started":"2024-06-30T13:01:20.54273Z","shell.execute_reply":"2024-06-30T13:01:20.549227Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"length of dataset in characters:  1115394\n","output_type":"stream"}]},{"cell_type":"code","source":"# let's look at the first 1000 characters\nprint(text[:1000])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T13:01:20.551998Z","iopub.execute_input":"2024-06-30T13:01:20.552742Z","iopub.status.idle":"2024-06-30T13:01:20.562881Z","shell.execute_reply.started":"2024-06-30T13:01:20.552643Z","shell.execute_reply":"2024-06-30T13:01:20.561713Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T13:01:20.564737Z","iopub.execute_input":"2024-06-30T13:01:20.565045Z","iopub.status.idle":"2024-06-30T13:01:20.592028Z","shell.execute_reply.started":"2024-06-30T13:01:20.565021Z","shell.execute_reply":"2024-06-30T13:01:20.590882Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\n\nstoi = {ch:i for i,ch in enumerate(chars)}\nitos = {i:ch for i,ch in enumerate(chars)}\n\nencode = lambda s: [stoi[c] for c in s]\ndecode = lambda l: \"\".join([itos[i] for i in l])","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:20.59395Z","iopub.execute_input":"2024-06-30T13:01:20.594279Z","iopub.status.idle":"2024-06-30T13:01:20.602437Z","shell.execute_reply.started":"2024-06-30T13:01:20.594253Z","shell.execute_reply":"2024-06-30T13:01:20.601375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(encode(\"hello\"))","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:20.868537Z","iopub.execute_input":"2024-06-30T13:01:20.869234Z","iopub.status.idle":"2024-06-30T13:01:20.874372Z","shell.execute_reply.started":"2024-06-30T13:01:20.8692Z","shell.execute_reply":"2024-06-30T13:01:20.873338Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[46, 43, 50, 50, 53]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(decode(encode(\"hello\")))","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:22.019374Z","iopub.execute_input":"2024-06-30T13:01:22.020116Z","iopub.status.idle":"2024-06-30T13:01:22.02496Z","shell.execute_reply.started":"2024-06-30T13:01:22.020083Z","shell.execute_reply":"2024-06-30T13:01:22.023991Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"hello\n","output_type":"stream"}]},{"cell_type":"code","source":"# let's now encode the entire text dataset and store it into a torch.Tensor\nimport torch\n\nprint(f\"No. of chars: {len(text)}\")\nprint(f\"No. of encoded integers: {len(encode(text))}\") # => 1115394; \nassert len(text)==len(encode(text)) #this confirms our ecoder is working fine\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:22.3908Z","iopub.execute_input":"2024-06-30T13:01:22.391166Z","iopub.status.idle":"2024-06-30T13:01:25.295797Z","shell.execute_reply.started":"2024-06-30T13:01:22.391139Z","shell.execute_reply":"2024-06-30T13:01:25.294659Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"No. of chars: 1115394\nNo. of encoded integers: 1115394\n","output_type":"stream"}]},{"cell_type":"code","source":"encoded_text = encode(text)\ndata = torch.tensor(encoded_text, dtype=torch.long)\n\nprint(data.shape, data.dtype)\n\nprint(data[:1000])","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.297578Z","iopub.execute_input":"2024-06-30T13:01:25.298027Z","iopub.status.idle":"2024-06-30T13:01:25.562518Z","shell.execute_reply.started":"2024-06-30T13:01:25.297999Z","shell.execute_reply":"2024-06-30T13:01:25.561482Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"torch.Size([1115394]) torch.int64\ntensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Let's now split up the data into train and validation sets\n# first 90% will be train, rest val\nprint(f\"Data Size: {len(data)}\")\nn = int(len(data)*0.9)\n\nprint(f\"90%: {len(data[:n])}| 10%: {len(data[n:])}\")\n\nprint(f\"90%: {len(data[:n])} + 10%: {len(data[n:])} =  {len(data[:n]) + len(data[n:])}\")\nassert len(data[:n]) + len(data[n:]) == len(data)\n\n\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.563708Z","iopub.execute_input":"2024-06-30T13:01:25.564092Z","iopub.status.idle":"2024-06-30T13:01:25.571823Z","shell.execute_reply.started":"2024-06-30T13:01:25.564059Z","shell.execute_reply":"2024-06-30T13:01:25.570706Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Data Size: 1115394\n90%: 1003854| 10%: 111540\n90%: 1003854 + 10%: 111540 =  1115394\n","output_type":"stream"}]},{"cell_type":"code","source":"block_size = 8 # also known as context length, that a transformer see\n\ntrain_data[:block_size+1]","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.573792Z","iopub.execute_input":"2024-06-30T13:01:25.574097Z","iopub.status.idle":"2024-06-30T13:01:25.584977Z","shell.execute_reply.started":"2024-06-30T13:01:25.574073Z","shell.execute_reply":"2024-06-30T13:01:25.583816Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\n\nprint(f\"input context-> target\")\nprint(\"=\"*50)\n\nfor t in range(block_size):    \n    print(f\"{x[:t+1]} -> {y[t]}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.586252Z","iopub.execute_input":"2024-06-30T13:01:25.586682Z","iopub.status.idle":"2024-06-30T13:01:25.595475Z","shell.execute_reply.started":"2024-06-30T13:01:25.586631Z","shell.execute_reply":"2024-06-30T13:01:25.594491Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"input context-> target\n==================================================\ntensor([18]) -> 47\ntensor([18, 47]) -> 56\ntensor([18, 47, 56]) -> 57\ntensor([18, 47, 56, 57]) -> 58\ntensor([18, 47, 56, 57, 58]) -> 1\ntensor([18, 47, 56, 57, 58,  1]) -> 15\ntensor([18, 47, 56, 57, 58,  1, 15]) -> 47\ntensor([18, 47, 56, 57, 58,  1, 15, 47]) -> 58\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\n\ndef get_batch(split):\n    data = train_data if split=='train' else val_data\n    \n    # This line generates batch_size random indices (ix) within the range from 0 to len(data) - block_size. \n    # The subtraction by block_size ensures thereâ€™s enough room to create sequences of length block_size.\n    ix = torch.randint(low=0, high=len(data)-block_size, size=(batch_size,)) # we get batch_size random integers within the range\n    \n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    \n    return x,y","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.59708Z","iopub.execute_input":"2024-06-30T13:01:25.597532Z","iopub.status.idle":"2024-06-30T13:01:25.607941Z","shell.execute_reply.started":"2024-06-30T13:01:25.597497Z","shell.execute_reply":"2024-06-30T13:01:25.607009Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"xb, yb = get_batch('train')\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\nprint('----')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:25.880784Z","iopub.execute_input":"2024-06-30T13:01:25.881475Z","iopub.status.idle":"2024-06-30T13:01:25.912195Z","shell.execute_reply.started":"2024-06-30T13:01:25.881441Z","shell.execute_reply":"2024-06-30T13:01:25.911137Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"inputs:\ntorch.Size([4, 8])\ntensor([[24, 43, 58,  5, 57,  1, 46, 43],\n        [44, 53, 56,  1, 58, 46, 39, 58],\n        [52, 58,  1, 58, 46, 39, 58,  1],\n        [25, 17, 27, 10,  0, 21,  1, 54]])\ntargets:\ntorch.Size([4, 8])\ntensor([[43, 58,  5, 57,  1, 46, 43, 39],\n        [53, 56,  1, 58, 46, 39, 58,  1],\n        [58,  1, 58, 46, 39, 58,  1, 46],\n        [17, 27, 10,  0, 21,  1, 54, 39]])\n----\n","output_type":"stream"}]},{"cell_type":"code","source":"for b in range(batch_size):\n    for t in range(block_size):\n        context = xb[b,:t+1]\n        target = yb[b, t]\n        \n        print(f\"when the input is: {context.tolist()}, the target is: {target}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:26.739472Z","iopub.execute_input":"2024-06-30T13:01:26.74015Z","iopub.status.idle":"2024-06-30T13:01:26.747036Z","shell.execute_reply.started":"2024-06-30T13:01:26.740116Z","shell.execute_reply":"2024-06-30T13:01:26.746026Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"when the input is: [24], the target is: 43\nwhen the input is: [24, 43], the target is: 58\nwhen the input is: [24, 43, 58], the target is: 5\nwhen the input is: [24, 43, 58, 5], the target is: 57\nwhen the input is: [24, 43, 58, 5, 57], the target is: 1\nwhen the input is: [24, 43, 58, 5, 57, 1], the target is: 46\nwhen the input is: [24, 43, 58, 5, 57, 1, 46], the target is: 43\nwhen the input is: [24, 43, 58, 5, 57, 1, 46, 43], the target is: 39\nwhen the input is: [44], the target is: 53\nwhen the input is: [44, 53], the target is: 56\nwhen the input is: [44, 53, 56], the target is: 1\nwhen the input is: [44, 53, 56, 1], the target is: 58\nwhen the input is: [44, 53, 56, 1, 58], the target is: 46\nwhen the input is: [44, 53, 56, 1, 58, 46], the target is: 39\nwhen the input is: [44, 53, 56, 1, 58, 46, 39], the target is: 58\nwhen the input is: [44, 53, 56, 1, 58, 46, 39, 58], the target is: 1\nwhen the input is: [52], the target is: 58\nwhen the input is: [52, 58], the target is: 1\nwhen the input is: [52, 58, 1], the target is: 58\nwhen the input is: [52, 58, 1, 58], the target is: 46\nwhen the input is: [52, 58, 1, 58, 46], the target is: 39\nwhen the input is: [52, 58, 1, 58, 46, 39], the target is: 58\nwhen the input is: [52, 58, 1, 58, 46, 39, 58], the target is: 1\nwhen the input is: [52, 58, 1, 58, 46, 39, 58, 1], the target is: 46\nwhen the input is: [25], the target is: 17\nwhen the input is: [25, 17], the target is: 27\nwhen the input is: [25, 17, 27], the target is: 10\nwhen the input is: [25, 17, 27, 10], the target is: 0\nwhen the input is: [25, 17, 27, 10, 0], the target is: 21\nwhen the input is: [25, 17, 27, 10, 0, 21], the target is: 1\nwhen the input is: [25, 17, 27, 10, 0, 21, 1], the target is: 54\nwhen the input is: [25, 17, 27, 10, 0, 21, 1, 54], the target is: 39\n","output_type":"stream"}]},{"cell_type":"code","source":"print(xb) # our input to the transformer","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:27.404964Z","iopub.execute_input":"2024-06-30T13:01:27.405877Z","iopub.status.idle":"2024-06-30T13:01:27.411556Z","shell.execute_reply.started":"2024-06-30T13:01:27.405842Z","shell.execute_reply":"2024-06-30T13:01:27.410528Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n        [44, 53, 56,  1, 58, 46, 39, 58],\n        [52, 58,  1, 58, 46, 39, 58,  1],\n        [25, 17, 27, 10,  0, 21,  1, 54]])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntorch.manual_seed(1337)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:28.291219Z","iopub.execute_input":"2024-06-30T13:01:28.291901Z","iopub.status.idle":"2024-06-30T13:01:28.299678Z","shell.execute_reply.started":"2024-06-30T13:01:28.291867Z","shell.execute_reply":"2024-06-30T13:01:28.298669Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x79a763a8b2d0>"},"metadata":{}}]},{"cell_type":"code","source":"emb = nn.Embedding(vocab_size, vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:30.103628Z","iopub.execute_input":"2024-06-30T13:01:30.104601Z","iopub.status.idle":"2024-06-30T13:01:30.112187Z","shell.execute_reply.started":"2024-06-30T13:01:30.104563Z","shell.execute_reply":"2024-06-30T13:01:30.111155Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Here we test the Embedding layer","metadata":{}},{"cell_type":"markdown","source":"It accepts a tensor as input","metadata":{}},{"cell_type":"code","source":"print(emb(torch.tensor(0))) # for a 1-d tensor it has generated below output\nprint(emb(torch.tensor(0)).shape) # the shape is 65, which are embeddings from the embedding lookup table","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:32.869502Z","iopub.execute_input":"2024-06-30T13:01:32.870386Z","iopub.status.idle":"2024-06-30T13:01:32.91224Z","shell.execute_reply.started":"2024-06-30T13:01:32.870351Z","shell.execute_reply":"2024-06-30T13:01:32.911277Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"tensor([ 0.1808, -0.0700, -0.3596, -0.9152,  0.6258,  0.0255,  0.9545,  0.0643,\n         0.3612,  1.1679, -1.3499, -0.5102,  0.2360, -0.2398, -0.9211,  1.5433,\n         1.3488, -0.1396,  0.2858,  0.9651, -2.0371,  0.4931,  1.4870,  0.5910,\n         0.1260, -1.5627, -1.1601, -0.3348,  0.4478, -0.8016,  1.5236,  2.5086,\n        -0.6631, -0.2513,  1.0101,  0.1215,  0.1584,  1.1340, -1.1539, -0.2984,\n        -0.5075, -0.9239,  0.5467, -1.4948, -1.2057,  0.5718, -0.5974, -0.6937,\n         1.6455, -0.8030,  1.3514, -0.2759, -1.5108,  2.1048,  2.7630, -1.7465,\n         1.4516, -1.5103,  0.8212, -0.2115,  0.7789,  1.5333,  1.6097, -0.4032,\n        -0.8345], grad_fn=<EmbeddingBackward0>)\ntorch.Size([65])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can pass a batch of input to the embedding layer, so let's pass our xb batch","metadata":{}},{"cell_type":"code","source":"xb.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:34.840386Z","iopub.execute_input":"2024-06-30T13:01:34.841058Z","iopub.status.idle":"2024-06-30T13:01:34.847744Z","shell.execute_reply.started":"2024-06-30T13:01:34.841024Z","shell.execute_reply":"2024-06-30T13:01:34.846312Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 8])"},"metadata":{}}]},{"cell_type":"code","source":"logits = emb(xb)\nB,T,C = logits.shape\nprint(B,T,C)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:35.780405Z","iopub.execute_input":"2024-06-30T13:01:35.780898Z","iopub.status.idle":"2024-06-30T13:01:35.786018Z","shell.execute_reply.started":"2024-06-30T13:01:35.780869Z","shell.execute_reply":"2024-06-30T13:01:35.785116Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"4 8 65\n","output_type":"stream"}]},{"cell_type":"markdown","source":"4 is the batch size\n\n8 is the block size (time-dimention)\n\n65 is the output embedding (channel -dimention)","metadata":{}},{"cell_type":"markdown","source":"Let's do some reshaping - this will come handy when we compute cross-entropy loss for our Bigram model","metadata":{}},{"cell_type":"code","source":"logits.view(B*T, C).shape # using view approach","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:46.496941Z","iopub.execute_input":"2024-06-30T13:01:46.497666Z","iopub.status.idle":"2024-06-30T13:01:46.503945Z","shell.execute_reply.started":"2024-06-30T13:01:46.497617Z","shell.execute_reply":"2024-06-30T13:01:46.502942Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 65])"},"metadata":{}}]},{"cell_type":"code","source":"logits.flatten(start_dim=0, end_dim=1).shape # using flatten approach","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:01:47.440218Z","iopub.execute_input":"2024-06-30T13:01:47.441105Z","iopub.status.idle":"2024-06-30T13:01:47.447979Z","shell.execute_reply.started":"2024-06-30T13:01:47.441069Z","shell.execute_reply":"2024-06-30T13:01:47.446803Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 65])"},"metadata":{}}]},{"cell_type":"markdown","source":"We can use any method, so I am chosing view, because I can use my pre computed B,T, and C there","metadata":{}},{"cell_type":"code","source":"class BigramLanguageModel(nn.Module):\n    def __init__(self, vocab_size):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n        \n    def forward(self, idx, targets=None):\n        logits = self.token_embedding_table(idx)\n        print(logits.shape)\n        if targets is None:\n            loss = None\n        else:\n            print(targets.shape)\n            \n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            \n            print(logits.shape)\n            print(targets.shape)\n            loss = F.cross_entropy(logits, targets)\n            print(loss.shape)\n        return logits, loss\n        \n    def generate(self, idx, max_new_tokens):\n        pass\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:11:39.192963Z","iopub.execute_input":"2024-06-30T13:11:39.193843Z","iopub.status.idle":"2024-06-30T13:11:39.201639Z","shell.execute_reply.started":"2024-06-30T13:11:39.193802Z","shell.execute_reply":"2024-06-30T13:11:39.200317Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model = BigramLanguageModel(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:11:39.928871Z","iopub.execute_input":"2024-06-30T13:11:39.929605Z","iopub.status.idle":"2024-06-30T13:11:39.934772Z","shell.execute_reply.started":"2024-06-30T13:11:39.929566Z","shell.execute_reply":"2024-06-30T13:11:39.933572Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model(xb)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:11:40.325499Z","iopub.execute_input":"2024-06-30T13:11:40.326684Z","iopub.status.idle":"2024-06-30T13:11:40.337447Z","shell.execute_reply.started":"2024-06-30T13:11:40.326615Z","shell.execute_reply":"2024-06-30T13:11:40.336085Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"torch.Size([4, 8, 65])\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(tensor([[[ 0.4431,  0.8079,  0.1164,  ...,  0.7518,  0.3750, -1.2435],\n          [-0.2245, -0.8710, -0.1792,  ..., -0.9120, -0.3722, -2.1224],\n          [ 1.3565,  1.4173, -1.4363,  ..., -0.3440,  0.1705,  0.2296],\n          ...,\n          [-0.3801,  0.7018, -0.2113,  ...,  2.6878, -0.0383, -0.5667],\n          [ 0.2069, -1.4096,  0.2898,  ...,  1.2784,  0.3223,  1.3288],\n          [-0.2245, -0.8710, -0.1792,  ..., -0.9120, -0.3722, -2.1224]],\n \n         [[-1.9387,  0.1355, -1.4978,  ...,  2.4457,  0.0596, -0.8411],\n          [ 0.0547,  0.2618,  1.3190,  ..., -0.5641, -0.1748,  0.1328],\n          [-1.0519,  0.5082,  0.5445,  ...,  1.5149,  0.7761, -2.2275],\n          ...,\n          [ 0.2069, -1.4096,  0.2898,  ...,  1.2784,  0.3223,  1.3288],\n          [ 1.4059, -0.4747,  2.3200,  ..., -0.9030, -1.3301, -0.3194],\n          [ 1.3565,  1.4173, -1.4363,  ..., -0.3440,  0.1705,  0.2296]],\n \n         [[-1.9676, -0.6505, -0.3899,  ..., -0.2830,  0.7560,  0.0279],\n          [ 1.3565,  1.4173, -1.4363,  ..., -0.3440,  0.1705,  0.2296],\n          [-0.3801,  0.7018, -0.2113,  ...,  2.6878, -0.0383, -0.5667],\n          ...,\n          [ 1.4059, -0.4747,  2.3200,  ..., -0.9030, -1.3301, -0.3194],\n          [ 1.3565,  1.4173, -1.4363,  ..., -0.3440,  0.1705,  0.2296],\n          [-0.3801,  0.7018, -0.2113,  ...,  2.6878, -0.0383, -0.5667]],\n \n         [[ 0.4268, -0.2317,  0.4364,  ..., -0.0395, -0.4824,  0.2704],\n          [ 1.1457, -1.3805, -1.2537,  ...,  0.9546,  0.3560,  1.2332],\n          [-0.9493,  1.6322, -0.2619,  ..., -0.5341, -2.1527,  1.7996],\n          ...,\n          [ 0.7683,  0.1575,  1.1619,  ..., -0.1675, -1.9079,  0.5961],\n          [-0.3801,  0.7018, -0.2113,  ...,  2.6878, -0.0383, -0.5667],\n          [ 0.7651, -0.3907,  0.0111,  ...,  1.5337,  1.1710,  0.7720]]],\n        grad_fn=<EmbeddingBackward0>),\n None)"},"metadata":{}}]},{"cell_type":"code","source":"logits, loss = model(xb, yb)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:16:54.601337Z","iopub.execute_input":"2024-06-30T13:16:54.601734Z","iopub.status.idle":"2024-06-30T13:16:54.607575Z","shell.execute_reply.started":"2024-06-30T13:16:54.601704Z","shell.execute_reply":"2024-06-30T13:16:54.606521Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"torch.Size([4, 8, 65])\ntorch.Size([4, 8])\ntorch.Size([32, 65])\ntorch.Size([32])\ntorch.Size([])\n","output_type":"stream"}]},{"cell_type":"code","source":"F.cross_entropy(logits, yb.view(-1))","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:22:14.730462Z","iopub.execute_input":"2024-06-30T13:22:14.731278Z","iopub.status.idle":"2024-06-30T13:22:14.738784Z","shell.execute_reply.started":"2024-06-30T13:22:14.731239Z","shell.execute_reply":"2024-06-30T13:22:14.737707Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"tensor(4.5564, grad_fn=<NllLossBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:23:04.635409Z","iopub.execute_input":"2024-06-30T13:23:04.635832Z","iopub.status.idle":"2024-06-30T13:23:04.640836Z","shell.execute_reply.started":"2024-06-30T13:23:04.6358Z","shell.execute_reply":"2024-06-30T13:23:04.639551Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"-np.log(1/65)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:23:24.347251Z","iopub.execute_input":"2024-06-30T13:23:24.347669Z","iopub.status.idle":"2024-06-30T13:23:24.354794Z","shell.execute_reply.started":"2024-06-30T13:23:24.347619Z","shell.execute_reply":"2024-06-30T13:23:24.353551Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"4.174387269895637"},"metadata":{}}]},{"cell_type":"markdown","source":"According to the cross entropy for given vocab size = 65, the expected loss value is ~4.17, \n\nand our calculated cross_entropy value for given batch is ~4.55, this represents a little skew in the dataset, though it is close, so let's proceed to next","metadata":{}},{"cell_type":"code","source":"logits, loss = model(xb)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:28:01.540369Z","iopub.execute_input":"2024-06-30T13:28:01.540881Z","iopub.status.idle":"2024-06-30T13:28:01.546133Z","shell.execute_reply.started":"2024-06-30T13:28:01.540848Z","shell.execute_reply":"2024-06-30T13:28:01.545039Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"torch.Size([4, 8, 65])\n","output_type":"stream"}]},{"cell_type":"code","source":"yb","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:32:03.777966Z","iopub.execute_input":"2024-06-30T13:32:03.778765Z","iopub.status.idle":"2024-06-30T13:32:03.785673Z","shell.execute_reply.started":"2024-06-30T13:32:03.778729Z","shell.execute_reply":"2024-06-30T13:32:03.784609Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n        [53, 56,  1, 58, 46, 39, 58,  1],\n        [58,  1, 58, 46, 39, 58,  1, 46],\n        [17, 27, 10,  0, 21,  1, 54, 39]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's try to generate next sequence given input xb or idx","metadata":{}},{"cell_type":"code","source":"idx = xb ","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:35:40.718423Z","iopub.execute_input":"2024-06-30T13:35:40.719311Z","iopub.status.idle":"2024-06-30T13:35:40.724091Z","shell.execute_reply.started":"2024-06-30T13:35:40.719272Z","shell.execute_reply":"2024-06-30T13:35:40.722706Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"logits, loss = model(idx)\n# focus only on the last time step\nlogits = logits[:, -1, :] # becomes (B, C)\nprint(logits.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:36:22.801812Z","iopub.execute_input":"2024-06-30T13:36:22.802775Z","iopub.status.idle":"2024-06-30T13:36:22.808821Z","shell.execute_reply.started":"2024-06-30T13:36:22.80274Z","shell.execute_reply":"2024-06-30T13:36:22.807711Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"torch.Size([4, 8, 65])\ntorch.Size([4, 65])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Since it is a sequence generation, so we are focusing on the last time step. That is comparable to yb, real target. ","metadata":{}},{"cell_type":"code","source":"# apply softmax to get probabilities\nprobs = F.softmax(logits, dim=-1) # (B, C)\nprint(probs)\nprint(probs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:36:54.065907Z","iopub.execute_input":"2024-06-30T13:36:54.066697Z","iopub.status.idle":"2024-06-30T13:36:54.077792Z","shell.execute_reply.started":"2024-06-30T13:36:54.06666Z","shell.execute_reply":"2024-06-30T13:36:54.076551Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"tensor([[0.0074, 0.0039, 0.0078, 0.0324, 0.0036, 0.0964, 0.0092, 0.0053, 0.0397,\n         0.0156, 0.0010, 0.0069, 0.0083, 0.0530, 0.0027, 0.0578, 0.0030, 0.0091,\n         0.0293, 0.0227, 0.0107, 0.0042, 0.0010, 0.0138, 0.0056, 0.0098, 0.0106,\n         0.0038, 0.0115, 0.0084, 0.0140, 0.0172, 0.0229, 0.0047, 0.0196, 0.0049,\n         0.0166, 0.0149, 0.0180, 0.0131, 0.0098, 0.0102, 0.0070, 0.0070, 0.0295,\n         0.0340, 0.0422, 0.0158, 0.0049, 0.0121, 0.0075, 0.0105, 0.0213, 0.0045,\n         0.0133, 0.0077, 0.0026, 0.0559, 0.0108, 0.0299, 0.0016, 0.0103, 0.0037,\n         0.0064, 0.0011],\n        [0.0432, 0.0459, 0.0026, 0.0053, 0.0087, 0.0070, 0.0148, 0.0046, 0.0090,\n         0.0069, 0.0173, 0.0299, 0.0151, 0.0212, 0.0140, 0.0096, 0.0121, 0.0118,\n         0.0182, 0.0034, 0.0208, 0.0037, 0.0116, 0.0041, 0.0077, 0.0073, 0.0091,\n         0.0106, 0.0027, 0.0034, 0.0041, 0.0198, 0.0117, 0.0120, 0.0070, 0.0154,\n         0.0074, 0.0114, 0.0242, 0.0068, 0.0204, 0.0098, 0.1098, 0.0351, 0.0094,\n         0.0130, 0.0011, 0.0027, 0.0134, 0.0189, 0.0139, 0.0039, 0.0705, 0.0208,\n         0.0139, 0.0021, 0.0178, 0.0208, 0.0276, 0.0072, 0.0270, 0.0043, 0.0079,\n         0.0132, 0.0140],\n        [0.0038, 0.0112, 0.0045, 0.0012, 0.0107, 0.0033, 0.0435, 0.0072, 0.0983,\n         0.0201, 0.0067, 0.0067, 0.0044, 0.0048, 0.0041, 0.0094, 0.0346, 0.0008,\n         0.0090, 0.0028, 0.1000, 0.0047, 0.0015, 0.0024, 0.0172, 0.0055, 0.0232,\n         0.0022, 0.0133, 0.0017, 0.0086, 0.0012, 0.0049, 0.0111, 0.0072, 0.0031,\n         0.0014, 0.0034, 0.0086, 0.0156, 0.0048, 0.0035, 0.0044, 0.0080, 0.0097,\n         0.0081, 0.0120, 0.0044, 0.0110, 0.0007, 0.0460, 0.0043, 0.0050, 0.0367,\n         0.0037, 0.0228, 0.0391, 0.0345, 0.0987, 0.0068, 0.0127, 0.0088, 0.0819,\n         0.0054, 0.0032],\n        [0.0175, 0.0055, 0.0082, 0.0075, 0.0062, 0.0270, 0.0055, 0.0087, 0.0459,\n         0.0029, 0.1341, 0.0074, 0.0108, 0.0111, 0.0022, 0.0051, 0.0158, 0.0181,\n         0.0069, 0.0235, 0.0647, 0.0678, 0.0069, 0.0267, 0.0052, 0.0024, 0.0045,\n         0.0381, 0.0041, 0.0044, 0.0052, 0.0108, 0.0039, 0.0175, 0.0195, 0.0029,\n         0.0014, 0.0031, 0.0062, 0.0016, 0.0086, 0.0029, 0.0059, 0.0306, 0.0119,\n         0.0263, 0.0060, 0.0015, 0.0061, 0.0272, 0.0146, 0.0246, 0.0091, 0.0125,\n         0.0028, 0.0107, 0.0125, 0.0018, 0.0076, 0.0095, 0.0172, 0.0015, 0.0378,\n         0.0263, 0.0177]], grad_fn=<SoftmaxBackward0>)\ntorch.Size([4, 65])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"torch.multinomial returns a tensor where each row contains num_samples indices sampled from the multinomial probability distribution located in the corresponding row of tensor input.","metadata":{}},{"cell_type":"code","source":"# sample from the distribution\nidx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\nprint(idx_next)\nprint(idx_next.shape)\n# append sampled index to the running sequence\nidx = torch.cat((idx, idx_next), dim=1) # (B, T+1)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:37:21.760468Z","iopub.execute_input":"2024-06-30T13:37:21.760869Z","iopub.status.idle":"2024-06-30T13:37:21.77812Z","shell.execute_reply.started":"2024-06-30T13:37:21.76084Z","shell.execute_reply":"2024-06-30T13:37:21.777094Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"tensor([[46],\n        [52],\n        [ 5],\n        [10]])\ntorch.Size([4, 1])\n","output_type":"stream"}]},{"cell_type":"code","source":"idx","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:37:32.907628Z","iopub.execute_input":"2024-06-30T13:37:32.908041Z","iopub.status.idle":"2024-06-30T13:37:32.915382Z","shell.execute_reply.started":"2024-06-30T13:37:32.90801Z","shell.execute_reply":"2024-06-30T13:37:32.914392Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"tensor([[24, 43, 58,  5, 57,  1, 46, 43, 46],\n        [44, 53, 56,  1, 58, 46, 39, 58, 52],\n        [52, 58,  1, 58, 46, 39, 58,  1,  5],\n        [25, 17, 27, 10,  0, 21,  1, 54, 10]])"},"metadata":{}}]},{"cell_type":"code","source":"yb","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:37:56.330009Z","iopub.execute_input":"2024-06-30T13:37:56.330399Z","iopub.status.idle":"2024-06-30T13:37:56.338024Z","shell.execute_reply.started":"2024-06-30T13:37:56.330369Z","shell.execute_reply":"2024-06-30T13:37:56.336908Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n        [53, 56,  1, 58, 46, 39, 58,  1],\n        [58,  1, 58, 46, 39, 58,  1, 46],\n        [17, 27, 10,  0, 21,  1, 54, 39]])"},"metadata":{}}]},{"cell_type":"code","source":"torch.cat([idx_next, yb[:,-1].view(-1,1)], dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:40:05.384048Z","iopub.execute_input":"2024-06-30T13:40:05.384831Z","iopub.status.idle":"2024-06-30T13:40:05.392885Z","shell.execute_reply.started":"2024-06-30T13:40:05.384796Z","shell.execute_reply":"2024-06-30T13:40:05.391707Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"tensor([[46, 39],\n        [52,  1],\n        [ 5, 46],\n        [10, 39]])"},"metadata":{}}]},{"cell_type":"markdown","source":"The first row(idx_next) represents the output generated by the model for given idx or(xb) as input. \n\nThe last row (yb) represents the target or expected output. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}